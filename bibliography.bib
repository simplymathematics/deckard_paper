@article{adversarialpatch,
	title        = {Adversarial patch},
	author       = {Brown, Tom B and Man{\'e}, Dandelion and Roy, Aurko and Abadi, Mart{\'\i}n and Gilmer, Justin},
	year         = 2017,
	journal      = {arXiv:1712.09665}
}
@article{aft_models,
	title        = {Survival analysis part II: multivariate data analysis--an introduction to concepts and methods},
	author       = {Bradburn, Mike J and Clark, Taane G and Love, Sharon B and Altman, Douglas Graham},
	year         = 2003,
	journal      = {British journal of cancer},
	publisher    = {Nature Publishing Group},
	volume       = 89,
	number       = 3,
	pages        = {431--436}
}
@inproceedings{strubell2020energy,
	title        = {Energy and policy considerations for modern deep learning research},
	author       = {Strubell, Emma and Ganesh, Ananya and McCallum, Andrew},
	year         = 2020,
	booktitle    = {Proceedings of the AAAI conference on artificial intelligence},
	volume       = 34,
	number       = {09},
	pages        = {13693--13696}
}
@article{rosenbacke2024ai,
	title        = {AI and XAI second opinion: the danger of false confirmation in human--AI collaboration},
	author       = {Rosenbacke, Rikard and Melhus, {\AA}sa and McKee, Martin and Stuckler, David},
	year         = 2024,
	journal      = {Journal of Medical Ethics},
	publisher    = {Institute of Medical Ethics}
}
@inproceedings{perry2023users,
	title        = {Do users write more insecure code with AI assistants?},
	author       = {Perry, Neil and Srivastava, Megha and Kumar, Deepak and Boneh, Dan},
	year         = 2023,
	booktitle    = {Proceedings of the 2023 ACM SIGSAC conference on computer and communications security},
	pages        = {2785--2799}
}
@inproceedings{jiang2012modeling,
	title        = {Modeling and verification of a dual chamber implantable pacemaker},
	author       = {Jiang, Zhihao and Pajic, Miroslav and Moarref, Salar and Alur, Rajeev and Mangharam, Rahul},
	year         = 2012,
	booktitle    = {International conference on tools and algorithms for the construction and analysis of systems},
	pages        = {188--203},
	organization = {Springer}
}
@article{leroy2009formally,
	title        = {A formally verified compiler back-end},
	author       = {Leroy, Xavier},
	year         = 2009,
	journal      = {Journal of Automated Reasoning},
	publisher    = {Springer},
	volume       = 43,
	pages        = {363--446}
}
@book{boeing777,
	title        = {An introduction to mechanical engineering},
	author       = {Wickert, Jonathan and Lewis, Kemper},
	year         = 2013,
	publisher    = {Cengage learning}
}
@inproceedings{bungert2023understanding,
	title        = {Understanding silent failures in medical image classification},
	author       = {Bungert, Till J and Kobelke, Levin and Jaeger, Paul F},
	year         = 2023,
	booktitle    = {International Conference on Medical Image Computing and Computer-Assisted Intervention},
	pages        = {400--410},
	organization = {Springer}
}
@book{hooks,
	title        = {Ain’t I A woman: Black women and feminism},
	author       = {Hooks, Bell},
	year         = 2015,
	publisher    = {Routledge, Taylor \& Francis Group},
	place        = {New York, New York}
}
@article{mcfowland2013fast,
	title        = {Fast generalized subset scan for anomalous pattern detection},
	author       = {McFowland, Edward and Speakman, Skyler and Neill, Daniel B},
	year         = 2013,
	journal      = {The Journal of Machine Learning Research},
	publisher    = {JMLR. org},
	volume       = 14,
	number       = 1,
	pages        = {1533--1561}
}
@article{chen2018detecting,
	title        = {Detecting backdoor attacks on deep neural networks by activation clustering},
	author       = {Chen, Bryant and Carvalho, Wilka and Baracaldo, Nathalie and Ludwig, Heiko and Edwards, Benjamin and Lee, Taesung and Molloy, Ian and Srivastava, Biplav},
	year         = 2018,
	journal      = {arXiv preprint arXiv:1811.03728}
}
@inproceedings{wang2018defensive,
	title        = {Defensive dropout for hardening deep neural networks under adversarial attacks},
	author       = {Wang, Siyue and Wang, Xiao and Zhao, Pu and Wen, Wujie and Kaeli, David and Chin, Peter and Lin, Xue},
	year         = 2018,
	booktitle    = {2018 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)},
	pages        = {1--8},
	organization = {IEEE}
}
@article{gao2017deepcloak,
	title        = {Deepcloak: Masking deep neural network models for robustness against adversarial samples},
	author       = {Gao, Ji and Wang, Beilun and Lin, Zeming and Xu, Weilin and Qi, Yanjun},
	year         = 2017,
	journal      = {arXiv preprint arXiv:1702.06763}
}
@article{crenshaw,
	title        = {Mapping the margins: Identity politics, intersectionality, and violence against women},
	author       = {Crenshaw, Kimberl{\'e}},
	year         = 1991,
	journal      = {Stanford Law Review},
	volume       = 43,
	number       = 6,
	pages        = {1241--1299}
}
@article{samuel1959some,
	title        = {Some studies in machine learning using the game of checkers},
	author       = {Samuel, Arthur L},
	year         = 1959,
	journal      = {IBM Journal of research and development},
	publisher    = {IBM},
	volume       = 3,
	number       = 3,
	pages        = {210--229}
}
@inproceedings{hidden_stratification,
	title        = {Hidden stratification causes clinically meaningful failures in machine learning for medical imaging},
	author       = {Oakden-Rayner, Luke and Dunnmon, Jared and Carneiro, Gustavo and R{\'e}, Christopher},
	year         = 2020,
	booktitle    = {Proceedings of the ACM conference on health, inference, and learning},
	pages        = {151--159}
}
@article{zhang2023deep,
	title        = {Deep long-tailed learning: A survey},
	author       = {Zhang, Yifan and Kang, Bingyi and Hooi, Bryan and Yan, Shuicheng and Feng, Jiashi},
	year         = 2023,
	journal      = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	publisher    = {IEEE},
	volume       = 45,
	number       = 9,
	pages        = {10795--10816}
}
@article{medical_failure_detection,
	title        = {Failure detection in deep neural networks for medical imaging},
	author       = {Ahmed, Sabeen and Dera, Dimah and Hassan, Saud Ul and Bouaynaya, Nidhal and Rasool, Ghulam},
	year         = 2022,
	journal      = {Frontiers in Medical Technology},
	publisher    = {Frontiers Media SA},
	volume       = 4,
	pages        = 919046
}
@article{medical_ML_methodology,
	title        = {Machine learning for medical imaging: methodological failures and recommendations for the future},
	author       = {Varoquaux, Ga{\"e}l and Cheplygina, Veronika},
	year         = 2022,
	journal      = {NPJ digital medicine},
	publisher    = {Nature Publishing Group UK London},
	volume       = 5,
	number       = 1,
	pages        = 48
}
@article{medical_reproducibility,
	title        = {Reproducibility of deep learning algorithms developed for medical imaging analysis: A systematic review},
	author       = {Moassefi, Mana and Rouzrokh, Pouria and Conte, Gian Marco and Vahdati, Sanaz and Fu, Tianyuan and Tahmasebi, Aylin and Younis, Mira and Farahani, Keyvan and Gentili, Amilcare and Kline, Timothy and others},
	year         = 2023,
	journal      = {Journal of Digital Imaging},
	publisher    = {Springer},
	volume       = 36,
	number       = 5,
	pages        = {2306--2312}
}
@misc{gorillas,
	title        = {Google’s photo app still can’t find gorillas. and neither can Apple’s.},
	author       = {Grant, Nico and Hill, Kashmir},
	year         = 2023,
	month        = {5},
	journal      = {The New York Times},
	publisher    = {The New York Times},
	url          = {https://www.nytimes.com/2023/05/22/technology/ai-photo-labels-google-apple.html}
}
@book{data_feminism,
	title        = {Data feminism},
	author       = {D’Ignazio, Catherine and Klein, Lauren F.},
	year         = 2023,
	publisher    = {The MIT Press},
	place        = {Cambridge, Massachusetts}
}
@article{ai_cost_comparison,
	title        = {Intelligence at any price? A criterion for defining AI},
	author       = {Nadin, Mihai},
	year         = 2023,
	journal      = {AI \& SOCIETY},
	publisher    = {Springer},
	volume       = 38,
	number       = 5,
	pages        = {1813--1817}
}
@misc{gsm-symbolic,
	title        = {GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models},
	author       = {Iman Mirzadeh and Keivan Alizadeh and Hooman Shahrokhi and Oncel Tuzel and Samy Bengio and Mehrdad Farajtabar},
	year         = 2024,
	url          = {https://arxiv.org/abs/2410.05229}
}
@article{todo,
	title        = {Intelligence at any price? A criterion for defining AI},
	author       = {Nadin, Mihai},
	year         = 2023,
	journal      = {AI \& SOCIETY},
	publisher    = {Springer},
	volume       = 38,
	number       = 5,
	pages        = {1813--1817}
}
@article{vgg,
	title        = {Very deep convolutional networks for large-scale image recognition},
	author       = {Simonyan, Karen and Zisserman, Andrew},
	year         = 2014,
	journal      = {arXiv preprint arXiv:1409.1556}
}
@misc{pricing_1,
	title        = {GPU pricing. Compute Engine: Virtual Machines (VMS). google cloud},
	author       = {Google},
	journal      = {Google Cloud Platform GPU Pricing},
	publisher    = {Google},
	url          = {https://cloud.google.com/compute/gpus-pricing}
}
@misc{pricing_2,
	title        = {GPU pricing. Compute Engine: Virtual Machines (VMS). google cloud},
	author       = {Google},
	journal      = {Google Cloud Platform GPU Pricing},
	publisher    = {Google},
	url          = {https://cloud.google.com/compute/vm-instance-pricing\#accelerator-optimised}
}
@inproceedings{ahn2003captcha,
	title        = {CAPTCHA: Using hard AI problems for security},
	author       = {Ahn, Luis von and Blum, Manuel and Hopper, Nicholas J and Langford, John},
	year         = 2003,
	booktitle    = {International conference on the theory and applications of cryptographic techniques},
	pages        = {294--311},
	organization = {Springer}
}
@article{ai_automotive,
	title        = {End to end learning for self-driving cars},
	author       = {Bojarski, Mariusz and Del Testa, Davide and Dworakowski, Daniel and Firner, Bernhard and Flepp, Beat and Goyal, Prasoon and Jackel, Lawrence D and Monfort, Mathew and Muller, Urs and Zhang, Jiakai and others},
	year         = 2016,
	journal      = {arXiv preprint arXiv:1604.07316}
}
@inproceedings{ai_aviation,
	title        = {A comparative study of machine learning techniques for aviation applications},
	author       = {Maheshwari, Apoorv and Davendralingam, Navindran and DeLaurentis, Daniel A},
	year         = 2018,
	booktitle    = {2018 Aviation Technology, Integration, and Operations Conference},
	pages        = 3980
}
@article{ai_industry,
	title        = {Machine learning in industrial control system (ICS) security: current landscape, opportunities and challenges},
	author       = {Koay, Abigail MY and Ko, Ryan K L and Hettema, Hinne and Radke, Kenneth},
	year         = 2023,
	journal      = {Journal of Intelligent Information Systems},
	publisher    = {Springer},
	volume       = 60,
	number       = 2,
	pages        = {377--405}
}
@article{ai_luggage,
	title        = {Modern computer vision techniques for x-ray testing in baggage inspection},
	author       = {Mery, Domingo and Svec, Erick and Arias, Marco and Riffo, Vladimir and Saavedra, Jose M and Banerjee, Sandipan},
	year         = 2016,
	journal      = {IEEE Transactions on Systems, Man, and Cybernetics: Systems},
	publisher    = {IEEE},
	volume       = 47,
	number       = 4,
	pages        = {682--692}
}
@article{ai_medical_imaging,
	title        = {Machine learning for medical imaging},
	author       = {Erickson, Bradley J and Korfiatis, Panagiotis and Akkus, Zeynettin and Kline, Timothy L},
	year         = 2017,
	journal      = {Radiographics},
	publisher    = {Radiological Society of North America},
	volume       = 37,
	number       = 2,
	pages        = {505--515}
}
@article{ai_prison,
	title        = {Machine learning and criminal justice: A systematic review of advanced methodology for recidivism risk prediction},
	author       = {Travaini, Guido Vittorio and Pacchioni, Federico and Bellumore, Silvia and Bosia, Marta and De Micco, Francesco},
	year         = 2022,
	journal      = {International journal of environmental research and public health},
	publisher    = {MDPI},
	volume       = 19,
	number       = 17,
	pages        = 10594
}
@inproceedings{ai_security,
	title        = {Dos and don'ts of machine learning in computer security},
	author       = {Arp, Daniel and Quiring, Erwin and Pendlebury, Feargus and Warnecke, Alexander and Pierazzi, Fabio and Wressnegger, Christian and Cavallaro, Lorenzo and Rieck, Konrad},
	year         = 2022,
	booktitle    = {31st USENIX Security Symposium (USENIX Security 22)},
	pages        = {3971--3988}
}
@inproceedings{al2017deep,
	title        = {Deep learning algorithm for autonomous driving using {GoogLeNet}},
	author       = {Al-Qizwini, Mohammed and Barjasteh, Iman and Al-Qassab, Hothaifa and Radha, Hayder},
	year         = 2017,
	booktitle    = {2017 IEEE Intelligent Vehicles Symposium (IV)},
	pages        = {89--96},
	organization = {IEEE}
}
@inproceedings{amaral2023kepler,
	title        = {Kepler: A Framework to Calculate the Energy Consumption of Containerized Applications},
	author       = {Amaral, Marcelo and Chen, Huamin and Chiba, Tatsuhiro and Nakazawa, Rina and Choochotkaew, Sunyanan and Lee, Eun Kyung and Eilam, Tamar},
	year         = 2023,
	booktitle    = {2023 IEEE 16th International Conference on Cloud Computing (CLOUD)},
	pages        = {69--71},
	doi          = {10.1109/CLOUD60044.2023.00017}
}
@article{art2018,
	title        = {Adversarial Robustness Toolbox v1.2.0},
	author       = {Nicolae, Maria-Irina and Sinn, Mathieu and Tran, Minh~Ngoc and Buesser, Beat and Rawat, Ambrish and Wistuba, Martin and Zantedeschi, Valentina and Baracaldo, Nathalie and Chen, Bryant and Ludwig, Heiko and Molloy, Ian and Edwards, Ben},
	year         = 2018,
	journal      = {CoRR},
	volume       = {1807.01069}
}
@article{athalye_obfuscated_2018,
	title        = {Obfuscated {Gradients} {Give} a {False} {Sense} of {Security}: {Circumventing} {Defenses} to {Adversarial} {Examples}},
	shorttitle   = {Obfuscated {Gradients} {Give} a {False} {Sense} of {Security}},
	author       = {Athalye, Anish and Carlini, Nicholas and Wagner, David},
	year         = 2018,
	month        = jul,
	journal      = {arXiv:1802.00420 [cs]},
	url          = {http://arxiv.org/abs/1802.00420},
	urldate      = {2020-10-01},
	abstract     = {We identify obfuscated gradients, a kind of gradient masking, as a phenomenon that leads to a false sense of security in defenses against adversarial examples. While defenses that cause obfuscated gradients appear to defeat iterative optimizationbased attacks, we ﬁnd defenses relying on this effect can be circumvented. We describe characteristic behaviors of defenses exhibiting the effect, and for each of the three types of obfuscated gradients we discover, we develop attack techniques to overcome it. In a case study, examining noncertiﬁed white-box-secure defenses at ICLR 2018, we ﬁnd obfuscated gradients are a common occurrence, with 7 of 9 defenses relying on obfuscated gradients. Our new attacks successfully circumvent 6 completely, and 1 partially, in the original threat model each paper considers.},
	language     = {en},
	keywords     = {Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security, Computer Science - Machine Learning},
	file         = {Athalye et al. - 2018 - Obfuscated Gradients Give a False Sense of Securit.pdf:C\:\\Users\\charlie\\Zotero\\storage\\36AD8ZHI\\Athalye et al. - 2018 - Obfuscated Gradients Give a False Sense of Securit.pdf:application/pdf}
}
@book{aviation,
	title        = {Developing safety-critical software: a practical guide for aviation software and DO-178C compliance},
	author       = {Rierson, Leanna},
	year         = 2017,
	publisher    = {CRC Press}
}
@book{aviation_compliance,
	title        = {Developing safety-critical software: a practical guide for aviation software and DO-178C compliance},
	author       = {Rierson, Leanna},
	year         = 2017,
	publisher    = {CRC Press}
}
@inproceedings{aviation_software,
	title        = {Applying lessons from safety-critical systems to security-critical software},
	author       = {Axelrod, C Warren},
	year         = 2011,
	booktitle    = {2011 IEEE Long Island Systems, Applications and Technology Conference},
	pages        = {1--6},
	organization = {IEEE}
}
@article{bailly2022effects,
	title        = {Effects of dataset size and interactions on the prediction performance of logistic regression and deep learning models},
	author       = {Bailly, Alexandre and Blanc, Corentin and Francis, {\'E}lie and Guillotin, Thierry and Jamal, Fadi and Wakim, B{\'e}chara and Roy, Pascal},
	year         = 2022,
	journal      = {Computer Methods and Programs in Biomedicine},
	publisher    = {Elsevier},
	volume       = 213,
	pages        = 106504
}
@article{banks2018driver,
	title        = {Driver error or designer error: Using the Perceptual Cycle Model to explore the circumstances surrounding the fatal Tesla crash on 7th May 2016},
	author       = {Banks, Victoria A and Plant, Katherine L and Stanton, Neville A},
	year         = 2018,
	journal      = {Safety science},
	publisher    = {Elsevier},
	volume       = 108,
	pages        = {278--285}
}
@article{bect_bayesian_2017,
	title        = {Bayesian subset simulation},
	author       = {Bect, Julien and Li, Ling and Vazquez, Emmanuel},
	year         = 2017,
	month        = jan,
	journal      = {SIAM/ASA Journal on Uncertainty Quantification},
	volume       = 5,
	number       = 1,
	pages        = {762--786},
	doi          = {10.1137/16M1078276},
	issn         = {2166-2525},
	url          = {http://arxiv.org/abs/1601.02557},
	urldate      = {2020-07-20},
	abstract     = {We consider the problem of estimating a probability of failure α, deﬁned as the volume of the excursion set of a function f : X ⊆ Rd → R above a given threshold, under a given probability measure on X. In this article, we combine the popular subset simulation algorithm (Au and Beck, Probab. Eng. Mech. 2001) and our sequential Bayesian approach for the estimation of a probability of failure (Bect, Ginsbourger, Li, Picheny and Vazquez, Stat. Comput. 2012). This makes it possible to estimate α when the number of evaluations of f is very limited and α is very small. The resulting algorithm is called Bayesian subset simulation (BSS). A key idea, as in the subset simulation algorithm, is to estimate the probabilities of a sequence of excursion sets of f above intermediate thresholds, using a sequential Monte Carlo (SMC) approach. A Gaussian process prior on f is used to deﬁne the sequence of densities targeted by the SMC algorithm, and drive the selection of evaluation points of f to estimate the intermediate probabilities. Adaptive procedures are proposed to determine the intermediate thresholds and the number of evaluations to be carried out at each stage of the algorithm. Numerical experiments illustrate that BSS achieves signiﬁcant savings in the number of function evaluations with respect to other Monte Carlo approaches.},
	language     = {en},
	keywords     = {Statistics - Computation},
	file         = {Bect et al. - 2017 - Bayesian subset simulation.pdf:C\:\\Users\\charlie\\Zotero\\storage\\CFEQS6UF\\Bect et al. - 2017 - Bayesian subset simulation.pdf:application/pdf}
}
@article{nelson2009misleading,
	title        = {Misleading learners: Co-opting your spam filter},
	author       = {Nelson, Blaine and Barreno, Marco and Jack Chi, Fuching and Joseph, Anthony D and Rubinstein, Benjamin IP and Saini, Udam and Sutton, Charles and Tygar, JD and Xia, Kai},
	year         = 2009,
	journal      = {Machine learning in cyber trust: Security, privacy, and reliability},
	publisher    = {Springer},
	pages        = {17--51}
}
@inproceedings{bernal2017safety++,
	title        = {Safety++ designing {IoT} and wearable systems for industrial safety through a user centered design approach},
	author       = {Bernal, Guillermo and Colombo, Sara and Al Ai Baky, Mohammed and Casalegno, Federico},
	year         = 2017,
	booktitle    = {Proceedings of the 10th International Conference on Pervasive Technologies Related to Assistive Environments},
	pages        = {163--170}
}
@article{biggio_evasion_2013,
	title        = {Evasion attacks against machine learning at test time},
	author       = {Biggio, Battista and Corona, Igino and Maiorca, Davide and Nelson, Blaine and {\v{S}}rndi{\'c}, Nedim and Laskov, Pavel and Giacinto, Giorgio and Roli, Fabio},
	year         = 2013,
	booktitle    = {Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2013, Prague, Czech Republic, September 23-27, 2013, Proceedings, Part III 13},
	pages        = {387--402},
	organization = {Springer}
}
@inproceedings{biggio_multiple_2009,
	title        = {Multiple {Classifier} {Systems} for {Adversarial} {Classification} {Tasks}},
	author       = {Biggio, Battista and Fumera, Giorgio and Roli, Fabio},
	year         = 2009,
	booktitle    = {Multiple {Classifier} {Systems}},
	publisher    = {Springer},
	address      = {Berlin, Heidelberg},
	series       = {Lecture {Notes} in {Computer} {Science}},
	pages        = {132--141},
	doi          = {10.1007/978-3-642-02326-2_14},
	isbn         = {978-3-642-02326-2},
	abstract     = {Pattern classification systems are currently used in security applications like intrusion detection in computer networks, spam filtering and biometric identity recognition. These are adversarial classification problems, since the classifier faces an intelligent adversary who adaptively modifies patterns (e.g., spam e-mails) to evade it. In these tasks the goal of a classifier is to attain both a high classification accuracy and a high hardness of evasion, but this issue has not been deeply investigated yet in the literature. We address it under the viewpoint of the choice of the architecture of a multiple classifier system. We propose a measure of the hardness of evasion of a classifier architecture, and give an analytical evaluation and comparison of an individual classifier and a classifier ensemble architecture. We finally report an experimental evaluation on a spam filtering task.},
	language     = {en},
	editor       = {Benediktsson, Jón Atli and Kittler, Josef and Roli, Fabio}
}
@article{biggio_poisoning_2013,
	title        = {Poisoning {Attacks} against {Support} {Vector} {Machines}},
	author       = {Biggio, Battista and Nelson, Blaine and Laskov, Pavel},
	year         = 2013,
	month        = mar,
	journal      = {arXiv:1206.6389 [cs, stat]},
	urldate      = {2020-11-02},
	abstract     = {We investigate a family of poisoning attacks against Support Vector Machines (SVM). Such attacks inject specially crafted training data that increases the SVM's test error. Central to the motivation for these attacks is the fact that most learning algorithms assume that their training data comes from a natural or well-behaved distribution. However, this assumption does not generally hold in security-sensitive settings. As we demonstrate, an intelligent adversary can, to some extent, predict the change of the SVM's decision function due to malicious input and use this ability to construct malicious data. The proposed attack uses a gradient ascent strategy in which the gradient is computed based on properties of the SVM's optimal solution. This method can be kernelized and enables the attack to be constructed in the input space even for non-linear kernels. We experimentally demonstrate that our gradient ascent procedure reliably identifies good local maxima of the non-convex validation error surface, which significantly increases the classifier's test error.},
	keywords     = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Statistics - Machine Learning},
	file         = {arXiv Fulltext PDF:C\:\\Users\\charlie\\Zotero\\storage\\MXH3JBV6\\Biggio et al. - 2013 - Poisoning Attacks against Support Vector Machines.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\charlie\\Zotero\\storage\\P4HDZ8AU\\1206.html:text/html}
}
@inproceedings{bloom2017self,
	title        = {Self-driving cars and data collection: Privacy perceptions of networked autonomous vehicles},
	author       = {Bloom, Cara and Tan, Joshua and Ramjohn, Javed and Bauer, Lujo},
	year         = 2017,
	booktitle    = {Symposium on Usable Privacy and Security (SOUPS)}
}
@article{blumer1989learnability,
	title        = {Learnability and the Vapnik-Chervonenkis dimension},
	author       = {Blumer, Anselm and Ehrenfeucht, Andrzej and Haussler, David and Warmuth, Manfred K},
	year         = 1989,
	journal      = {Journal of the ACM},
	volume       = 36,
	number       = 4,
	pages        = {929--965}
}
@inproceedings{braking,
	title        = {Autonomous braking system via deep reinforcement learning},
	author       = {Hyunmin Chae and Chang Mook Kang and ByeoungDo Kim and Jaekyum Kim and Chung Choo Chung and Jun Won Choi},
	year         = 2017,
	booktitle    = {{IEEE} 20th International conference on intelligent transportation systems ({ITSC})}
}
@inproceedings{buolamwini2018gender,
	title        = {Gender shades: Intersectional accuracy disparities in commercial gender classification},
	author       = {Buolamwini, Joy and Gebru, Timnit},
	year         = 2018,
	booktitle    = {Conference on fairness, accountability and transparency},
	pages        = {77--91},
	organization = {PMLR}
}
@article{cao2019generalization,
	title        = {Generalization bounds of stochastic gradient descent for wide and deep neural networks},
	author       = {Cao, Yuan and Gu, Quanquan},
	year         = 2019,
	journal      = {Advances in neural information processing systems},
	volume       = 32
}
@article{carlini_towards_2017,
	title        = {Towards evaluating the robustness of neural networks},
	author       = {Carlini, Nicholas and Wagner, David},
	year         = 2017,
	booktitle    = {2017 IEEE symposium on security and privacy (sp)},
	pages        = {39--57},
	organization = {Ieee}
}
@article{chakraborty_adversarial_2018,
	title        = {Adversarial Attacks and Defences: {A} Survey},
	author       = {Chakraborty, Anirban and Alam, Manaar and Dey, Vishal and Chattopadhyay, Anupam and Mukhopadhyay, Debdeep},
	year         = 2018,
	journal      = {arXiv:1810.00069 [cs, stat]}
}
@article{chakraborty2018adversarial,
	title        = {Adversarial attacks and defences: A survey},
	author       = {Chakraborty, Anirban and Alam, Manaar and Dey, Vishal and Chattopadhyay, Anupam and Mukhopadhyay, Debdeep},
	year         = 2018,
	journal      = {arXiv:1810.00069}
}
@article{chambolle2004algorithm,
	title        = {An algorithm for total variation minimization and applications},
	author       = {Chambolle, Antonin},
	year         = 2004,
	journal      = {Journal of Mathematical imaging and vision},
	publisher    = {Springer},
	volume       = 20,
	number       = 1,
	pages        = {89--97}
}
@article{ching2017opportunities,
	title        = {Opportunities and obstacles for deep learning in biology and medicine},
	author       = {Ching, Travers and Himmelstein, Daniel~S. and Beaulieu-Jones, Brett~K. and Kalinin, Alexandr~A. and Do, Brian~T. and Way, Gregory~P. and Ferrero, Enrico and Agapow, Paul-Michael and Zietz, Michael and Hoffman, Michael~M. and Xie, Wei and Rosen, Gail~L. and Lengerich, Benjamin~J. and Israeli, Johnny and Lanchantin, Jack and Woloszynek, Stephen and Carpenter, Anne~E. and Shrikumar, Avanti and Xu, Jinbo and Cofer, Evan~M. and Lavender, Christopher~A. and Turaga, Srinivas~C. and Alexandari, Amr~M. and Lu, Zhiyong and Harris, David~J. and DeCaprio, Dave and Qi, Yanjun and Kundaje, Anshul and Peng, Yifan and Wiley, Laura~K. and Segler, Marwin~H.~S. and Boca, Simina~M. and Swamidass, S.~ Joshua and Huang, Austin and Gitter, Anthony and Greene, Casey~S.},
	year         = 2017,
	journal      = {Journal of the Royal Society Interface},
	volume       = 15,
	number       = 141
}
@inproceedings{choquette2021label,
	title        = {Label-only membership inference attacks},
	author       = {Choquette-Choo, Christopher A and Tramer, Florian and Carlini, Nicholas and Papernot, Nicolas},
	year         = 2021,
	booktitle    = {International conference on machine learning},
	pages        = {1964--1974},
	organization = {PMLR}
}
@inproceedings{chou2023applicability,
	title        = {Applicability of Deep Learning Model Trainings on Embedded GPU Devices: An Empirical Study},
	author       = {Chou, Po-Hsuan and Wang, Chao and Mei, Chih-Shuo},
	year         = 2023,
	booktitle    = {2023 12th Mediterranean Conference on Embedded Computing (MECO)},
	pages        = {1--4},
	organization = {IEEE}
}
@article{christmann_robustness_nodate,
	title        = {On {Robustness} {Properties} of {Convex} {Risk} {Minimization} {Methods} for {Pattern} {Recognition}},
	author       = {Christmann, Andreas and Steinwart, Ingo},
	pages        = 28,
	abstract     = {The paper brings together methods from two disciplines: machine learning theory and robust statistics. We argue that robustness is an important aspect and we show that many existing machine learning methods based on the convex risk minimization principle have − besides other good properties − also the advantage of being robust. Robustness properties of machine learning methods based on convex risk minimization are investigated for the problem of pattern recognition. Assumptions are given for the existence of the inﬂuence function of the classiﬁers and for bounds on the inﬂuence function. Kernel logistic regression, support vector machines, least squares and the AdaBoost loss function are treated as special cases. Some results on the robustness of such methods are also obtained for the sensitivity curve and the maxbias, which are two other robustness criteria. A sensitivity analysis of the support vector machine is given.},
	language     = {en},
	file         = {christmann04a.pdf:C\:\\Users\\charlie\\Zotero\\storage\\A3EZEX5B\\christmann04a.pdf:application/pdf}
}
@article{chung1988labelings,
	title        = {Labelings of graphs},
	author       = {Chung, Fan RK},
	year         = 1988,
	journal      = {Selected topics in graph theory},
	volume       = 3,
	pages        = {151--168}
}
@article{cifar,
	title        = {Learning multiple layers of features from tiny images},
	author       = {Krizhevsky, Alex and Hinton, Geoffrey and others},
	year         = 2009,
	publisher    = {Toronto, ON, Canada}
}
@inproceedings{cintas_detecting_2020,
	title        = {Detecting {Adversarial} {Attacks} via {Subset} {Scanning} of {Autoencoder} {Activations} and {Reconstruction} {Error}},
	author       = {Cintas, Celia and Speakman, Skyler and Akinwande, Victor and Ogallo, William and Weldemariam, Komminist and Sridharan, Srihari and McFowland, Edward},
	year         = 2020,
	month        = jul,
	booktitle    = {Proceedings of the {Twenty}-{Ninth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	address      = {Yokohama, Japan},
	pages        = {876--882},
	doi          = {10.24963/ijcai.2020/122},
	isbn         = {978-0-9992411-6-5},
	url          = {https://www.ijcai.org/proceedings/2020/122},
	urldate      = {2020-11-03},
	abstract     = {Reliably detecting attacks in a given set of inputs is of high practical relevance because of the vulnerability of neural networks to adversarial examples. These altered inputs create a security risk in applications with real-world consequences, such as self-driving cars, robotics and ﬁnancial services. We propose an unsupervised method for detecting adversarial attacks in inner layers of autoencoder (AE) networks by maximizing a non-parametric measure of anomalous node activations. Previous work in this space has shown AE networks can detect anomalous images by thresholding the reconstruction error produced by the ﬁnal layer. Furthermore, other detection methods rely on data augmentation or specialized training techniques which must be asserted before training time. In contrast, we use subset scanning methods from the anomalous pattern detection domain to enhance detection power without labeled examples of the noise, retraining or data augmentation methods. In addition to an anomalous “score” our proposed method also returns the subset of nodes within the AE network that contributed to that score. This will allow future work to pivot from detection to visualisation and explainability. Our scanning approach shows consistently higher detection power than existing detection methods across several adversarial noise models and a wide range of perturbation strengths.},
	language     = {en},
	file         = {Cintas et al. - 2020 - Detecting Adversarial Attacks via Subset Scanning .pdf:C\:\\Users\\charlie\\Zotero\\storage\\RU2HGKV3\\Cintas et al. - 2020 - Detecting Adversarial Attacks via Subset Scanning .pdf:application/pdf}
}
@article{colbrook2021can,
	title        = {Can stable and accurate neural networks be computed},
	author       = {Colbrook, Matthew~J. and Antun, Vegard and Hansen, Anders~C.},
	year         = 2021,
	journal      = {On the barriers of deep learning and Smale’s 18th problem. arXiv},
	volume       = 2101
}
@article{concordance,
	title        = {A practical perspective on the concordance index for the evaluation and selection of prognostic time-to-event models},
	author       = {Longato, Enrico and Vettoretti, Martina and Di Camillo, Barbara},
	year         = 2020,
	journal      = {Journal of biomedical informatics},
	publisher    = {Elsevier},
	volume       = 108,
	pages        = 103496
}
@article{corsaro1982something,
	title        = {Something old and something new: The importance of prior ethnography in the collection and analysis of audiovisual data},
	author       = {Corsaro, William A},
	year         = 1982,
	journal      = {Sociological Methods \& Research},
	publisher    = {Sage Publications},
	volume       = 11,
	number       = 2,
	pages        = {145--166}
}
@article{cosentino2019search,
	title        = {The search for sparse, robust neural networks},
	author       = {Cosentino, Justin and Zaiter, Federico and Pei, Dan and Zhu, Jun},
	year         = 2019,
	journal      = {arXiv:1912.02386}
}
@article{croce_reliable_2020,
	title        = {Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks},
	author       = {Croce, Francesco and Hein, Matthias},
	year         = 2020,
	booktitle    = {International conference on machine learning},
	pages        = {2206--2216},
	organization = {PMLR}
}
@article{daher2018cloud,
	title        = {Cloud storage comparative analysis amazon simple storage vs. Microsoft azure blob storage},
	author       = {Daher, Zouheir and Hajjdiab, Hassan},
	year         = 2018,
	journal      = {International Journal of Machine Learning and Computing},
	volume       = 8,
	number       = 1,
	pages        = {85--9}
}
@article{daya_graph-based_2019,
	title        = {A {Graph}-{Based} {Machine} {Learning} {Approach} for {Bot} {Detection}},
	author       = {Daya, Abbas Abou and Salahuddin, Mohammad A. and Limam, Noura and Boutaba, Raouf},
	year         = 2019,
	month        = 2,
	journal      = {arXiv:1902.08538 [cs]},
	url          = {http://arxiv.org/abs/1902.08538},
	urldate      = {2020-11-03},
	language     = {en}
}
@article{dayarathna2015data,
	title        = {Data center energy consumption modeling: A survey},
	author       = {Dayarathna, Miyuru and Wen, Yonggang and Fan, Rui},
	year         = 2015,
	journal      = {IEEE Communications surveys \& tutorials},
	publisher    = {IEEE},
	volume       = 18,
	number       = 1,
	pages        = {732--794}
}




@inproceedings{deepfool,
	title        = {Deepfool: a simple and accurate method to fool deep neural networks},
	author       = {Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Frossard, Pascal},
	year         = 2016,
	booktitle    = {Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages        = {2574--2582}
}
@article{desislavov2021compute,
	title        = {Compute and energy consumption trends in deep learning inference},
	author       = {Desislavov, Radosvet and Mart{\'\i}nez-Plumed, Fernando and Hern{\'a}ndez-Orallo, Jos{\'e}},
	year         = 2021,
	howpublished = {arXiv preprint arXiv:2109.05472}
}
@inproceedings{discretization,
	title        = {Defending against whitebox adversarial attacks via randomized discretization},
	author       = {Zhang, Yuchen and Liang, Percy},
	year         = 2019,
	booktitle    = {The 22nd International Conference on Artificial Intelligence and Statistics},
	pages        = {684--693},
	organization = {PMLR}
}
@article{distributed_attacks,
	title        = {Machine Learning Approaches for Combating Distributed Denial of Service Attacks in Modern Networking Environments},
	author       = {Aljuhani, Ahamed},
	year         = 2021,
	journal      = {IEEE Access},
	volume       = 9,
	number       = {},
	pages        = {42236--42264},
	doi          = {10.1109/ACCESS.2021.3062909}
}
@inproceedings{dohmatob_generalized_2019,
	title        = {Generalized {No} {Free} {Lunch} {Theorem} for {Adversarial} {Robustness}},
	author       = {Dohmatob, Elvis},
	year         = 2019,
	booktitle    = {Proceedings of the 36th International Conference on Machine Learning},
	series       = {PMLR},
	volume       = 97
}
@misc{dvc,
	title        = {{DVC}--{Data Version Control}},
	author       = {{DVC Authors}},
	year         = 2023,
	url          = {https://github.com/iterative/dvc.org},
	howpublished = {Github}
}
@article{evans2001gender,
	title        = {Gender and age influence on fatality risk from the same physical impact determined using two-car crashes},
	author       = {Evans, Leonard and Gerrish, Peter H},
	year         = 2001,
	journal      = {SAE transactions},
	publisher    = {JSTOR},
	pages        = {1336--1341}
}
@article{feature_squeezing,
	title        = {Feature squeezing: Detecting adversarial examples in deep neural networks},
	author       = {Xu, Weilin and Evans, David and Qi, Yanjun},
	year         = 2017,
	journal      = {arXiv:1704.01155}
}
@misc{Feswing_2023,
	title        = {Chatgpt and generative AI are booming, but the costs can be extraordinary},
	author       = {Feswing, KiL},
	year         = 2023,
	month        = apr,
	journal      = {CNBC},
	publisher    = {CNBC},
	url          = {https://www.cnbc.com/2023/03/13/chatgpt-and-generative-ai-are-booming-but-at-a-very-expensive-price.html}
}
@article{fgm,
	title        = {Explaining and harnessing adversarial examples},
	author       = {Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
	year         = 2014,
	journal      = {arXiv:1412.6572}
}
@article{finlayson2018adversarial,
	title        = {Adversarial Attacks Against Medical Deep Learning Systems},
	author       = {Finlayson, Samuel G and Chung, Hyung Won and Kohane, Isaac S and Beam, Andrew L},
	year         = 2018,
	journal      = {arXiv:1804.05296}
}
@article{floridi2020gpt,
	title        = {GPT-3: Its nature, scope, limits, and consequences},
	author       = {Floridi, Luciano and Chiriatti, Massimo},
	year         = 2020,
	journal      = {Minds and Machines},
	publisher    = {Springer},
	volume       = 30,
	pages        = {681--694}
}
@article{formal_adversarial,
	title        = {Adversarial robustness of deep neural networks: A survey from a formal verification perspective},
	author       = {Meng, Mark Huasong and Bai, Guangdong and Teo, Sin Gee and Hou, Zhe and Xiao, Yan and Lin, Yun and Dong, Jin Song},
	year         = 2022,
	journal      = {IEEE Transactions on Dependable and Secure Computing},
	publisher    = {IEEE}
}
@inproceedings{fredrikson_model_2015,
	title        = {Model {Inversion} {Attacks} that {Exploit} {Confidence} {Information} and {Basic} {Countermeasures}},
	author       = {Fredrikson, Matt and Jha, Somesh and Ristenpart, Thomas},
	year         = 2015,
	booktitle    = {Proceedings of the 22nd {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security} - {CCS} '15},
	publisher    = {ACM Press},
	address      = {Denver, Colorado, USA},
	pages        = {1322--1333},
	doi          = {10.1145/2810103.2813677},
	isbn         = {978-1-4503-3832-5},
	url          = {http://dl.acm.org/citation.cfm?doid=2810103.2813677},
	urldate      = {2020-11-02},
	abstract     = {Machine-learning (ML) algorithms are increasingly utilized in privacy-sensitive applications such as predicting lifestyle choices, making medical diagnoses, and facial recognition. In a model inversion attack, recently introduced in a case study of linear classiﬁers in personalized medicine by Fredrikson et al. [13], adversarial access to an ML model is abused to learn sensitive genomic information about individuals. Whether model inversion attacks apply to settings outside theirs, however, is unknown.},
	language     = {en},
	file         = {Fredrikson et al. - 2015 - Model Inversion Attacks that Exploit Confidence In.pdf:C\:\\Users\\charlie\\Zotero\\storage\\6A5APDC5\\Fredrikson et al. - 2015 - Model Inversion Attacks that Exploit Confidence In.pdf:application/pdf}
}
@article{fukuda1992theory,
	title        = {Theory and applications of neural networks for industrial control systems},
	author       = {Fukuda, Toshio and Shibata, Takanori},
	year         = 1992,
	journal      = {IEEE Transactions on industrial electronics},
	publisher    = {IEEE},
	volume       = 39,
	number       = 6,
	pages        = {472--489}
}
@article{tpe_params,
	title        = {Tree-structured parzen estimator: Understanding its algorithm components and their roles for better empirical performance},
	author       = {Watanabe, Shuhei},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2304.11127}
}
@inproceedings{gauss_aug,
	title        = {Efficient Defenses Against Adversarial Attacks},
	author       = {Zantedeschi, Valentina and Nicolae, Maria-Irina and Rawat, Ambrish},
	year         = 2017,
	booktitle    = {Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security},
	location     = {Dallas, Texas, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {AISec '17},
	pages        = {39–49},
	isbn         = 9781450352024,
	numpages     = 11,
	keywords     = {deep neural network, model security, defenses, adversarial learning}
}
@inproceedings{gauss_out,
	title        = {Certified Robustness to Adversarial Examples with Differential Privacy},
	author       = {Lecuyer, Mathias and Atlidakis, Vaggelis and Geambasu, Roxana and Hsu, Daniel and Jana, Suman},
	year         = 2019,
	booktitle    = {2019 IEEE Symposium on Security and Privacy (SP)},
	pages        = {656--672}
}
@article{gichoya2022ai,
	title        = {AI recognition of patient race in medical imaging: a modelling study},
	author       = {Gichoya, Judy Wawira and Banerjee, Imon and Bhimireddy, Ananth Reddy and Burns, John L and Celi, Leo Anthony and Chen, Li-Ching and Correa, Ramon and Dullerud, Natalie and Ghassemi, Marzyeh and Huang, Shih-Cheng and others},
	year         = 2022,
	journal      = {The Lancet Digital Health},
	publisher    = {Elsevier},
	volume       = 4,
	number       = 6,
	pages        = {e406--e414}
}
@book{gormley2015elasticsearch,
	title        = {Elasticsearch: the definitive guide: a distributed real-time search and analytics engine},
	author       = {Gormley, Clinton and Tong, Zachary},
	year         = 2015,
	publisher    = {" O'Reilly Media, Inc."}
}
@article{granziol2022learning,
	title        = {Learning rates as a function of batch size: A random matrix theory approach to neural network training},
	author       = {Granziol, Diego and Zohren, Stefan and Roberts, Stephen},
	year         = 2022,
	journal      = {Journal of Machine Learning Research},
	volume       = 23,
	number       = 173,
	pages        = {1--65}
}
@article{grigorescu2020survey,
	title        = {A survey of deep learning techniques for autonomous driving},
	author       = {Grigorescu, Sorin and Trasnea, Bogdan and Cocias, Tiberiu and Macesanu, Gigel},
	year         = 2020,
	journal      = {Journal of Field Robotics},
	publisher    = {Wiley Online Library},
	volume       = 37,
	number       = 3,
	pages        = {362--386}
}
@article{guo2023comprehensive,
	title        = {A comprehensive evaluation framework for deep model robustness},
	author       = {Guo, Jun and Bao, Wei and Wang, Jiakai and Ma, Yuqing and Gao, Xinghai and Xiao, Gang and Liu, Aishan and Dong, Jian and Liu, Xianglong and Wu, Wenjun},
	year         = 2023,
	journal      = {Pattern Recognition},
	publisher    = {Elsevier},
	volume       = 137,
	pages        = 109308
}
@article{hadj2018continuation,
	title        = {Continuation of {Nesterov}’s smoothing for regression with structured sparsity in high-dimensional neuroimaging},
	author       = {Hadj-Selem, Fouad and L{\"o}fstedt, Tommy and Dohmatob, Elvis and Frouin, Vincent and Dubois, Mathieu and Guillemot, Vincent and Duchesnay, Edouard},
	year         = 2018,
	journal      = {IEEE Transactions on Medical Imaging},
	publisher    = {IEEE},
	volume       = 37,
	number       = 11,
	pages        = {2403--2413}
}
@inproceedings{hamming,
	title        = {Global robustness evaluation of deep neural networks with provable guarantees for the hamming distance},
	author       = {Ruan, Wenjie and Wu, Min and Sun, Youcheng and Huang, Xiaowei and Kroening, Daniel and Kwiatkowska, Marta},
	year         = 2019,
	organization = {IJCAI}
}
@inproceedings{hasselbring2017microservice,
	title        = {Microservice architectures for scalability, agility and reliability in e-commerce},
	author       = {Hasselbring, Wilhelm and Steinacker, Guido},
	year         = 2017,
	booktitle    = {2017 IEEE International Conference on Software Architecture Workshops (ICSAW)},
	pages        = {243--246},
	organization = {IEEE}
}
@article{high_conf,
	title        = {Lie to Me: A Soft Threshold Defense Method for Adversarial Examples of Remote Sensing Images},
	author       = {Chen, Li and Xiao, Jun and Zou, Pu and Li, Haifeng},
	year         = 2021,
	journal      = {IEEE Geoscience and Remote Sensing Letters},
	volume       = {},
	number       = {},
	pages        = {1--5},
	doi          = {10.1109/LGRS.2021.3096244}
}
@article{hochreiter1998vanishing,
	title        = {The vanishing gradient problem during learning recurrent neural nets and problem solutions},
	author       = {Hochreiter, Sepp},
	year         = 1998,
	journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
	publisher    = {World Scientific},
	volume       = 6,
	number       = {02},
	pages        = {107--116}
}
@inbook{hoffstein_pipher_silverman_2010,
	title        = {Complexity Theory and P vs NP},
	author       = {Hoffstein, Jeffrey and Pipher, Jill and Silverman, Joseph H.},
	year         = 2010,
	booktitle    = {An introduction to mathematical cryptography},
	publisher    = {Springer},
	pages        = {258--262},
	chapter      = 4
}
@inproceedings{hopskipjump,
	title        = {{HopSkipJumpAttack}: A query-efficient decision-based attack},
	author       = {Chen, Jianbo and Jordan, Michael I and Wainwright, Martin J},
	year         = 2020,
	booktitle    = {{IEEE} symposium on security and privacy (sp)},
	pages        = {1277--1294},
	organization = {IEEE}
}
@misc{hydra,
	title        = {Hydra -- A framework for elegantly configuring complex applications},
	author       = {Omry Yadan},
	year         = 2019,
	url          = {https://github.com/facebookresearch/hydra},
	howpublished = {Github}
}
@article{ici,
	title        = {Graphical calibration curves and the integrated calibration index (ICI) for survival models},
	author       = {Austin, Peter C and Harrell Jr, Frank E and van Klaveren, David},
	year         = 2020,
	journal      = {Statistics in Medicine},
	publisher    = {Wiley Online Library},
	volume       = 39,
	number       = 21,
	pages        = {2714--2742}
}
@article{icoh,
	title        = {GLOBAL ESTIMATES OF OCCUPATIONAL  ACCIDENTS AND WORK-RELATED ILLNESSES 2017},
	author       = {ICOH},
	year         = 2017,
	journal      = {International Commission on Occupational Health`},
	publisher    = {ICOH},
	url          = {http://www.icohweb.org/site/images/news/pdf/Report\%20Global\%20Estimates\%20of\%20Occupational\%20Accidents\%20and\%20Work-related\%20Illnesses\%202017\%20rev1.pdf}
}
@book{IEC61508,
	title        = {IEC 61508 Safety and Functional Safety},
	author       = {\mbox{International Electrotechnical Commission}},
	year         = 2010,
	publisher    = {International Electrotechnical Commission},
	edition      = {2nd}
}
@book{IEC62034,
	title        = {IEC 62304 Medical Device Software - Software Life Cycle Processes},
	author       = {\mbox{International Electrotechnical Commission}},
	year         = 2006,
	publisher    = {International Electrotechnical Commission},
	edition      = {2nd}
}
@article{imageenhance,
	title        = {Relationship between entropy and SNR changes in image enhancement},
	author       = {Krbcova, Zuzana and Kukal, Jaromir},
	year         = 2017,
	journal      = {EURASIP Journal on Image and Video Processing},
	publisher    = {Springer},
	volume       = 2017,
	number       = 1,
	pages        = {1--8}
}
@article{inkawhich_adversarial_2018,
	title        = {Adversarial {Attacks} for {Optical} {Flow}-{Based} {Action} {Recognition} {Classifiers}},
	author       = {Inkawhich, Nathan and Inkawhich, Matthew and Chen, Yiran and Li, Hai},
	year         = 2018,
	month        = nov,
	journal      = {arXiv:1811.11875 [cs]},
	url          = {http://arxiv.org/abs/1811.11875},
	urldate      = {2020-09-17},
	abstract     = {The success of deep learning research has catapulted deep models into production systems that our society is becoming increasingly dependent on, especially in the image and video domains. However, recent work has shown that these largely uninterpretable models exhibit glaring security vulnerabilities in the presence of an adversary. In this work, we develop a powerful untargeted adversarial attack for action recognition systems in both white-box and black-box settings. Action recognition models differ from image-classiﬁcation models in that their inputs contain a temporal dimension, which we explicitly target in the attack. Drawing inspiration from image classiﬁer attacks, we create new attacks which achieve state-of-the-art success rates on a two-stream classiﬁer trained on the UCF-101 dataset. We ﬁnd that our attacks can signiﬁcantly degrade a model’s performance with sparsely and imperceptibly perturbed examples. We also demonstrate the transferability of our attacks to black-box action recognition systems.},
	language     = {en},
	keywords     = {Computer Science - Computer Vision and Pattern Recognition},
	file         = {Inkawhich et al. - 2018 - Adversarial Attacks for Optical Flow-Based Action .pdf:C\:\\Users\\charlie\\Zotero\\storage\\KAR3FYXU\\Inkawhich et al. - 2018 - Adversarial Attacks for Optical Flow-Based Action .pdf:application/pdf}
}
@inproceedings{intermittent,
	title        = {Timing is Almost Everything: Realistic Evaluation of the Very Short Intermittent DDoS Attacks},
	author       = {Park, Jeman and Nyang, DaeHun and Mohaisen, Aziz},
	year         = 2018,
	booktitle    = {2018 16th Annual Conference on Privacy, Security and Trust (PST)},
	volume       = {},
	number       = {},
	pages        = {1--10},
	doi          = {10.1109/PST.2018.8514210}
}
@misc{iso26262,
	title        = {{ISO} 26262-1:2011, Road vehicles --- Functional safety},
	author       = {\mbox{International~Standards~Organization}},
	year         = 2018,
	howpublished = {\href{https://www.iso.org/standard/43464.html}{https://www.iso.org/standard/43464.html} (visited 2022-04-20)}
}

@misc{wandb,
title = {Experiment Tracking with Weights and Biases},
year = {2020},
note = {Software available from wandb.com},
url={https://www.wandb.com/},
author = {Biewald, Lukas},
}

@book{jahan2016multi,
	title        = {Multi-criteria decision analysis for supporting the selection of engineering materials in product design},
	author       = {Jahan, Ali and Edwards, Kevin L and Bahraminasab, Marjan},
	year         = 2016,
	publisher    = {Butterworth-Heinemann}
}
@inproceedings{jakubovitz2018improving,
	title        = {Improving dnn robustness to adversarial attacks using jacobian regularization},
	author       = {Jakubovitz, Daniel and Giryes, Raja},
	year         = 2018,
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)},
	pages        = {514--529}
}
@inproceedings{jang_objective_2017,
	title        = {Objective {Metrics} and {Gradient} {Descent} {Algorithms} for {Adversarial} {Examples} in {Machine} {Learning}},
	author       = {Jang, Uyeong and Wu, Xi and Jha, Somesh},
	year         = 2017,
	month        = dec,
	booktitle    = {Proceedings of the 33rd {Annual} {Computer} {Security} {Applications} {Conference}},
	publisher    = {ACM},
	address      = {Orlando FL USA},
	pages        = {262--277},
	doi          = {10.1145/3134600.3134635},
	isbn         = {978-1-4503-5345-8},
	url          = {https://dl.acm.org/doi/10.1145/3134600.3134635},
	urldate      = {2020-11-02},
	abstract     = {Fueled by massive amounts of data, models produced by machinelearning (ML) algorithms are being used in diverse domains where security is a concern, such as, automotive systems, finance, health-care, computer vision, speech recognition, naturallanguage processing, and malware detection. Of particular concern is use of ML in cyberphysical systems, such as driverless cars and aviation, where the presence of an adversary can cause serious consequences. In this paper we focus on attacks caused by adversarial samples, which are inputs crafted by adding small, often imperceptible, perturbations to force a ML model to misclassify. We present a simple gradient-descent based algorithm for finding adversarial samples, which performs well in comparison to existing algorithms. The second issue that this paper tackles is that of metrics. We present a novel metric based on few computer-vision algorithms for measuring the quality of adversarial samples.},
	language     = {en},
	file         = {Jang et al. - 2017 - Objective Metrics and Gradient Descent Algorithms .pdf:C\:\\Users\\charlie\\Zotero\\storage\\AWDDBQE7\\Jang et al. - 2017 - Objective Metrics and Gradient Descent Algorithms .pdf:application/pdf}
}
@article{jian2022pruning,
	title        = {Pruning Adversarially Robust Neural Networks without Adversarial Examples},
	author       = {Jian, Tong and Wang, Zifeng and Wang, Yanzhi and Dy, Jennifer and Ioannidis, Stratis},
	year         = 2022,
	journal      = {arXiv:2210.04311}
}
@misc{k8s,
	title        = {Kubernetes--an open source system for managing containerized applications},
	author       = {Kubernetes},
	year         = 2019,
	month        = {June},
	url          = {https://github.com/kubernetes/kubernetes},
	howpublished = {Github}
}
@misc{k8s-size,
	title        = {Octoverse Projects},
	author       = {Github},
	year         = 2019,
	journal      = {The State of the Octoverse},
	publisher    = {Github.com},
	url          = {https://octoverse.github.com/2018/projects.html}
}
@article{kamal2017study,
	title        = {A study on the security of password hashing based on gpu based, password cracking using high-performance cloud computing},
	author       = {Kamal, Parves},
	year         = 2017
}
@book{kleinbaum1996survival,
	title        = {Survival analysis a self-learning text},
	author       = {Kleinbaum, David G and Klein, Mitchel},
	year         = 1996,
	publisher    = {Springer}
}
@article{ko_loss-driven_2019,
	title        = {Loss-{Driven} {Adversarial} {Ensemble} {Deep} {Learning} for {On}-{Line} {Time} {Series} {Analysis}},
	author       = {Ko, Hyungjin and Lee, Jaewook and Byun, Junyoung and Son, Bumho and Park, Saerom},
	year         = 2019,
	month        = jan,
	journal      = {Sustainability},
	volume       = 11,
	number       = 12,
	pages        = 3489,
	doi          = {10.3390/su11123489},
	url          = {https://www.mdpi.com/2071-1050/11/12/3489},
	urldate      = {2020-11-02},
	copyright    = {http://creativecommons.org/licenses/by/3.0/},
	note         = {Number: 12 Publisher: Multidisciplinary Digital Publishing Institute},
	abstract     = {Developing a robust and sustainable system is an important problem in which deep learning models are used in real-world applications. Ensemble methods combine diverse models to improve performance and achieve robustness. The analysis of time series data requires dealing with continuously incoming instances; however, most ensemble models suffer when adapting to a change in data distribution. Therefore, we propose an on-line ensemble deep learning algorithm that aggregates deep learning models and adjusts the ensemble weight based on loss value in this study. We theoretically demonstrate that the ensemble weight converges to the limiting distribution, and, thus, minimizes the average total loss from a new regret measure based on adversarial assumption. We also present an overall framework that can be applied to analyze time series. In the experiments, we focused on the on-line phase, in which the ensemble models predict the binary class for the simulated data and the financial and non-financial real data. The proposed method outperformed other ensemble approaches. Moreover, our method was not only robust to the intentional attacks but also sustainable in data distribution changes. In the future, our algorithm can be extended to regression and multiclass classification problems.},
	language     = {en},
	keywords     = {adaptive learning, ensemble deep learning, on-line learning, time series analysis},
	file         = {Snapshot:C\:\\Users\\charlie\\Zotero\\storage\\2MWPWFGD\\3489.html:text/html;Full Text PDF:C\:\\Users\\charlie\\Zotero\\storage\\GWZ7CFVU\\Ko et al. - 2019 - Loss-Driven Adversarial Ensemble Deep Learning for.pdf:application/pdf;Snapshot:C\:\\Users\\charlie\\Zotero\\storage\\ACQARLLN\\3489.html:text/html}
}
@article{koch2021reduced,
	title        = {Reduced, reused and recycled: The life of a dataset in machine learning research},
	author       = {Koch, Bernard and Denton, Emily and Hanna, Alex and Foster, Jacob G},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2112.01716}
}
@article{kotyan2022adversarial,
	title        = {Adversarial robustness assessment: Why in evaluation both L0 and L\infty{} attacks are necessary},
	author       = {Kotyan, Shashank and Vargas, Danilo Vasconcellos},
	year         = 2022,
	journal      = {PLoS ONE},
	volume       = 17,
	number       = 4,
	pages        = {e0265723}
}
@inproceedings{label_smoothing,
	title        = {Adversarial Perturbations of Deep Neural Networks},
	author       = {D. Warde-Farley and I. Goodfellow},
	year         = 2017,
	booktitle    = {Perturbations, Optimization, and Statistics},
	publisher    = {The MIT Press, Cambridge, Massachusetts},
	editor       = {T. Hazan , G. Papandreou, D. Tarlow}
}
@article{lachin1981introduction,
	title        = {Introduction to sample size determination and power analysis for clinical trials},
	author       = {Lachin, John M},
	year         = 1981,
	journal      = {Controlled clinical trials},
	publisher    = {Elsevier},
	volume       = 2,
	number       = 2,
	pages        = {93--113}
}
@inproceedings{lam2004new,
	title        = {New design-to-test software strategies accelerate time-to-market},
	author       = {Lam, Hau},
	year         = 2004,
	booktitle    = {IEEE/CPMT/SEMI 29th International Electronics Manufacturing Technology Symposium (IEEE Cat. No. 04CH37585)},
	pages        = {140--143},
	organization = {IEEE}
}
@article{lambert2004parametric,
	title        = {Parametric accelerated failure time models with random effects and an application to kidney transplant survival},
	author       = {Lambert, Philippe and Collett, Dave and Kimber, Alan and Johnson, Rachel},
	year         = 2004,
	journal      = {Statistics in medicine},
	publisher    = {Wiley Online Library},
	volume       = 23,
	number       = 20,
	pages        = {3177--3192}
}
@article{lawless1995methods,
	title        = {Methods for the estimation of failure distributions and rates from automobile warranty data},
	author       = {Lawless, Jerry and Hu, Joan and Cao, Jin},
	year         = 1995,
	journal      = {Lifetime Data Analysis},
	publisher    = {Springer},
	volume       = 1,
	pages        = {227--240}
}
@inproceedings{legriel2010approximating,
	title        = {Approximating the pareto front of multi-criteria optimization problems},
	author       = {Legriel, Julien and Le Guernic, Colas and Cotton, Scott and Maler, Oded},
	year         = 2010,
	booktitle    = {International Conference on Tools and Algorithms for the Construction and Analysis of Systems},
	pages        = {69--83},
	organization = {Springer}
}
@inproceedings{leurent2020sha,
	title        = {{SHA-1} is a shambles: First {Chosen-Prefix} collision on {SHA-1} and application to the {PGP} web of trust},
	author       = {Leurent, Ga{\"e}tan and Peyrin, Thomas},
	year         = 2020,
	booktitle    = {29th USENIX security symposium (USENIX security 20)},
	pages        = {1839--1856}
}
@article{li_general_2016,
	title        = {A {General} {Retraining} {Framework} for {Scalable} {Adversarial} {Classification}},
	author       = {Li, Bo and Vorobeychik, Yevgeniy and Chen, Xinyun},
	year         = 2016,
	month        = nov,
	journal      = {arXiv:1604.02606 [cs, stat]},
	url          = {http://arxiv.org/abs/1604.02606},
	urldate      = {2020-09-17},
	abstract     = {Traditional classiﬁcation algorithms assume that training and test data come from similar distributions. This assumption is violated in adversarial settings, where malicious actors modify instances to evade detection. A number of custom methods have been developed for both adversarial evasion attacks and robust learning. We propose the ﬁrst systematic and general-purpose retraining framework which can: a) boost robustness of an arbitrary learning algorithm, in the face of b) a broader class of adversarial models than any prior methods. We show that, under natural conditions, the retraining framework minimizes an upper bound on optimal adversarial risk, and show how to extend this result to account for approximations of evasion attacks. Extensive experimental evaluation demonstrates that our retraining methods are nearly indistinguishable from state-of-the-art algorithms for optimizing adversarial risk, but are more general and far more scalable. The experiments also conﬁrm that without retraining, our adversarial framework dramatically reduces the effectiveness of learning. In contrast, retraining signiﬁcantly boosts robustness to evasion attacks without signiﬁcantly compromising overall accuracy.},
	language     = {en},
	keywords     = {Computer Science - Computer Science and Game Theory, Computer Science - Machine Learning, Statistics - Machine Learning},
	file         = {Li et al. - 2016 - A General Retraining Framework for Scalable Advers.pdf:C\:\\Users\\charlie\\Zotero\\storage\\NGCPLE3C\\Li et al. - 2016 - A General Retraining Framework for Scalable Advers.pdf:application/pdf}
}

@misc{keras,
author = {François Chollet },
title = {keras},
year = {2015},
publisher = {GitHub},
journal = {GitHub repository},
howpublished = {\url{https://github.com/fchollet/keras}},
}

@inproceedings{li2021membership,
	title        = {Membership leakage in label-only exposures},
	author       = {Li, Zheng and Zhang, Yang},
	year         = 2021,
	booktitle    = {Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security},
	pages        = {880--895}
}
@article{lifelines,
	title        = {lifelines: survival analysis in Python},
	author       = {Cameron Davidson-Pilon},
	year         = 2019,
	journal      = {Journal of Open Source Software},
	publisher    = {The Open Journal},
	volume       = 4,
	number       = 40,
	pages        = 1317
}
@article{liu2013development,
	title        = {Development of Accelerated Failure-free Test Method for Automotive Alternator Magnet},
	author       = {Liu, Qiang and Ismail, Azianti and Jung, Won},
	year         = 2013,
	journal      = {Journal of the Society of Korea Industrial and Systems Engineering},
	publisher    = {Society of Korea Industrial and System Engineering},
	volume       = 36,
	number       = 4,
	pages        = {92--99}
}
@article{liu2023goat,
	title        = {Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks},
	author       = {Liu, Tiedong and Low, Bryan Kian Hsiang},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2305.14201}
}
@misc{llama,
	title        = {Facebookresearch/llama: Inference code for Llama Models},
	author       = {Facebookresearch},
	journal      = {GitHub},
	publisher    = {Facebook Research},
	url          = {https://github.com/facebookresearch/llama}
}
@inproceedings{lowd_adversarial_2005,
	title        = {Adversarial learning},
	author       = {Lowd, Daniel and Meek, Christopher},
	year         = 2005,
	month        = aug,
	booktitle    = {Proceedings of the eleventh {ACM} {SIGKDD} international conference on {Knowledge} discovery in data mining},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {{KDD} '05},
	pages        = {641--647},
	doi          = {10.1145/1081870.1081950},
	isbn         = {978-1-59593-135-1},
	url          = {https://doi.org/10.1145/1081870.1081950},
	urldate      = {2020-11-02},
	abstract     = {Many classification tasks, such as spam filtering, intrusion detection, and terrorism detection, are complicated by an adversary who wishes to avoid detection. Previous work on adversarial classification has made the unrealistic assumption that the attacker has perfect knowledge of the classifier [2]. In this paper, we introduce the adversarial classifier reverse engineering (ACRE) learning problem, the task of learning sufficient information about a classifier to construct adversarial attacks. We present efficient algorithms for reverse engineering linear classifiers with either continuous or Boolean features and demonstrate their effectiveness using real data from the domain of spam filtering.},
	keywords     = {adversarial classification, linear classifiers, spam}
}
@article{lu2020gender,
	title        = {Gender bias in neural natural language processing},
	author       = {Lu, Kaiji and Mardziel, Piotr and Wu, Fangjing and Amancharla, Preetam and Datta, Anupam},
	year         = 2020,
	journal      = {Logic, Language, and Security: Essays Dedicated to Andre Scedrov on the Occasion of His 65th Birthday},
	publisher    = {Springer},
	pages        = {189--202}
}
@article{ma2020imbalanced,
	title        = {Imbalanced Gradients: A Subtle Cause of Overestimated Adversarial Robustness},
	author       = {Ma, Xingjun and Jiang, Linxi and Huang, Hanxun and Weng, Zejia and Bailey, James and Jiang, Yu-Gang},
	year         = 2020,
	journal      = {arXiv:2006.13726}
}
@article{ma2022state,
	title        = {A state-of-the-art survey on solving non-IID data in Federated Learning},
	author       = {Ma, Xiaodong and Zhu, Jia and Lin, Zhihao and Chen, Shanxuan and Qin, Yangjie},
	year         = 2022,
	journal      = {Future Generation Computer Systems},
	publisher    = {Elsevier},
	volume       = 135,
	pages        = {244--258}
}
@article{madry2017towards,
	title        = {Towards deep learning models resistant to adversarial attacks},
	author       = {Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
	year         = 2017,
	journal      = {arXiv:1706.06083}
}
@article{makary2016medical,
	title        = {Medical error---the third leading cause of death in the {US}},
	author       = {Makary, Martin A and Daniel, Michael},
	year         = 2016,
	journal      = {{BMJ}},
	publisher    = {British Medical Journal Publishing Group},
	volume       = 353
}
@article{meeker1998accelerated,
	title        = {Accelerated degradation tests: modeling and analysis},
	author       = {Meeker, William Q and Escobar, Luis A and Lu, C Joseph},
	year         = 1998,
	journal      = {Technometrics},
	publisher    = {Taylor \& Francis},
	volume       = 40,
	number       = 2,
	pages        = {89--99}
}
@article{meyers,
	title        = {Safety-critical computer vision: An empirical survey of adversarial evasion attacks and defenses on computer vision systems},
	author       = {Meyers, Charles and L\"{o}fstedt, Tommy and Elmroth, Erik},
	year         = 2023,
	journal      = {Springer Artificial Intelligence Review}
}
@article{meyers_aft,
	title        = {A Systematic Approach to Robustness Modelling},
	author       = {Meyers and Reza and L\"{o}fstedt and Elmroth},
	year         = 2023,
	journal      = {Springer Artificial Intelligence Review}
}
@article{miller_adversarial_2020,
	title        = {Adversarial {Learning} {Targeting} {Deep} {Neural} {Network} {Classification}: {A} {Comprehensive} {Review} of {Defenses} {Against} {Attacks}},
	shorttitle   = {Adversarial {Learning} {Targeting} {Deep} {Neural} {Network} {Classification}},
	author       = {Miller, David J. and Xiang, Zhen and Kesidis, George},
	year         = 2020,
	month        = mar,
	journal      = {Proceedings of the IEEE},
	volume       = 108,
	number       = 3,
	pages        = {402--433},
	doi          = {10.1109/JPROC.2020.2970615},
	issn         = {0018-9219, 1558-2256},
	url          = {https://IEEExplore.IEEE.org/document/9013065/},
	urldate      = {2020-08-12},
	language     = {en},
	file         = {Miller et al. - 2020 - Adversarial Learning Targeting Deep Neural Network.pdf:C\:\\Users\\charlie\\Zotero\\storage\\VV3I4V2C\\Miller et al. - 2020 - Adversarial Learning Targeting Deep Neural Network.pdf:application/pdf}
}
@article{min_curious_2020,
	title        = {The {Curious} {Case} of {Adversarially} {Robust} {Models}: {More} {Data} {Can} {Help}, {Double} {Descend}, or {Hurt} {Generalization}},
	shorttitle   = {The {Curious} {Case} of {Adversarially} {Robust} {Models}},
	author       = {Min, Yifei and Chen, Lin and Karbasi, Amin},
	year         = 2020,
	month        = jun,
	journal      = {arXiv:2002.11080 [cs, stat]},
	url          = {http://arxiv.org/abs/2002.11080},
	urldate      = {2020-10-02},
	abstract     = {Adversarial training has shown its ability in producing models that are robust to perturbations on the input data, but usually at the expense of decrease in the standard accuracy. To mitigate this issue, it is commonly believed that more training data will eventually help such adversarially robust models generalize better on the benign/unperturbed test data. In this paper, however, we challenge this conventional belief and show that more training data can hurt the generalization of adversarially robust models in the classiﬁcation problems. We ﬁrst investigate the Gaussian mixture classiﬁcation with a linear loss and identify three regimes based on the strength of the adversary. In the weak adversary regime, more data improves the generalization of adversarially robust models. In the medium adversary regime, with more training data, the generalization loss exhibits a double descent curve, which implies the existence of an intermediate stage where more training data hurts the generalization. In the strong adversary regime, more data almost immediately causes the generalization error to increase. Then we move to the analysis of a two-dimensional classiﬁcation problem with a 0-1 loss. We prove that more data always hurts the generalization performance of adversarially trained models with large perturbations. To complement our theoretical results, we conduct empirical studies on Gaussian mixture classiﬁcation, support vector machines (SVMs), and linear regression.},
	language     = {en},
	keywords     = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file         = {Min et al. - 2020 - The Curious Case of Adversarially Robust Models M.pdf:C\:\\Users\\charlie\\Zotero\\storage\\AZLGP9IT\\Min et al. - 2020 - The Curious Case of Adversarially Robust Models M.pdf:application/pdf}
}
@article{mnist,
	title        = {The mnist database of handwritten digit images for machine learning research},
	author       = {Deng, Li},
	year         = 2012,
	journal      = {IEEE Signal Processing Magazine},
	publisher    = {IEEE},
	volume       = 29,
	number       = 6,
	pages        = {141--142}
}
@article{monmasson2011fpgas,
	title        = {FPGAs in industrial control applications},
	author       = {Monmasson, Eric and Idkhajine, Lahoucine and Cirstea, Marcian N and Bahri, Imene and Tisan, Alin and Naouar, Mohamed Wissem},
	year         = 2011,
	journal      = {IEEE Transactions on Industrial informatics},
	publisher    = {IEEE},
	volume       = 7,
	number       = 2,
	pages        = {224--243}
}
@misc{msft_water,
	title        = {A.I. tools fueled a 34\% spike in Microsoft's water consumption, and one city with its data centers is concerned about the effect on residential supply},
	author       = {O'Brien, Matt and Fingerhut, Hannah and Press, The Associated},
	year         = 2023,
	month        = sep,
	journal      = {Fortune},
	publisher    = {Fortune},
	url          = {https://fortune.com/2023/09/09/ai-chatgpt-usage-fuels-spike-in-microsoft-water-consumption/}
}
@book{nelson2010behavior,
	title        = {Behavior of machine learning algorithms in adversarial environments},
	author       = {Nelson, Blaine Alan},
	year         = 2010,
	publisher    = {University of California, Berkeley}
}
@misc{nhtsa,
	title        = {Critical Reasons for Crashes Investigated in the National Motor Vehicle Crash Causation Survey},
	author       = {National Highway Transportation Safety Administration's (NHTSA) National Center for Statistics and Analysis},
	year         = 2015,
	publisher    = {US Department of Transportation},
	howpublished = {\href{https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/812115}{https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/812115} (visited 2022-04-20)}
}
@misc{noauthor_cross-dataset_nodate,
	title        = {Cross-dataset time series anomaly detection for cloud systems {\textbar} {Proceedings} of the 2019 {USENIX} {Conference} on {Usenix} {Annual} {Technical} {Conference}},
	url          = {https://dl.acm.org/doi/10.5555/3358807.3358898},
	urldate      = {2020-11-02},
	file         = {Cross-dataset time series anomaly detection for cloud systems | Proceedings of the 2019 USENIX Conference on Usenix Annual Technical Conference:C\:\\Users\\charlie\\Zotero\\storage\\X76DR7WP\\3358807.html:text/html}
}
@article{nsga2,
	title        = {A fast and elitist multiobjective genetic algorithm: NSGA-II},
	author       = {Deb, Kalyanmoy and Pratap, Amrit and Agarwal, Sameer and Meyarivan, TAMT},
	year         = 2002,
	journal      = {IEEE transactions on evolutionary computation},
	publisher    = {IEEE},
	volume       = 6,
	number       = 2,
	pages        = {182--197}
}
@misc{OECD,
	title        = {{OECD} statistics},
	author       = {The Organisation for Economic Co-operation and Development},
	year         = 2020,
	journal      = {{OECD} Statistics},
	publisher    = {International Transport Forum},
	howpublished = {\href{https://stats.oecd.org}{https://stats.oecd.org/} (visited 2022-04-20)}
}
@misc{openllama,
	title        = {Open Llamma},
	author       = {openlm-research},
	journal      = {GitHub},
	publisher    = {openlm-research},
	url          = {https://github.com/openlm-research/open\%5Fllama}
}
@inproceedings{optuna,
	title        = {Optuna: A next-generation hyperparameter optimization framework},
	author       = {Akiba, Takuya and Sano, Shotaro and Yanase, Toshihiko and Ohta, Takeru and Koyama, Masanori},
	year         = 2019,
	booktitle    = {Proceedings of the 25th ACM SIGKDD},
	pages        = {2623--2631}
}
@inproceedings{orekondy2019knockoff,
	title        = {Knockoff nets: Stealing functionality of black-box models},
	author       = {Orekondy, Tribhuvanesh and Schiele, Bernt and Fritz, Mario},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages        = {4954--4963}
}
@inproceedings{ozaki2020multiobjective,
	title        = {Multiobjective tree-structured parzen estimator for computationally expensive optimization problems},
	author       = {Ozaki, Yoshihiko and Tanigaki, Yuki and Watanabe, Shuhei and Onishi, Masaki},
	year         = 2020,
	booktitle    = {Proceedings of the 2020 genetic and evolutionary computation conference},
	pages        = {533--541}
}
@article{ozaki2022multiobjective,
	title        = {Multiobjective tree-structured Parzen estimator},
	author       = {Ozaki, Yoshihiko and Tanigaki, Yuki and Watanabe, Shuhei and Nomura, Masahiro and Onishi, Masaki},
	year         = 2022,
	journal      = {Journal of Artificial Intelligence Research},
	volume       = 73,
	pages        = {1209--1250}
}
@article{pakdemirli2019artificial,
	title        = {Artificial intelligence in radiology: friend or foe? Where are we now and where are we heading?},
	author       = {Pakdemirli, Emre},
	year         = 2019,
	journal      = {Acta radiologica open},
	publisher    = {SAGE Publications Sage UK: London, England},
	volume       = 8,
	number       = 2
}
@article{panchal2024reusable,
	title        = {Reusable MLOps: Reusable Deployment, Reusable Infrastructure and Hot-Swappable Machine Learning models and services},
	author       = {Panchal, D and Verma, P and Baran, I and Musgrove, D and Lu, D},
	year         = 2024,
	journal      = {arXiv preprint arXiv:2403.00787}
}
@article{pantoja2021concordance,
	title        = {Concordance measures and time-dependent ROC methods},
	author       = {Pantoja-Galicia, Norberto and Okereke, Olivia I and Blacker, Deborah and Betensky, Rebecca A},
	year         = 2021,
	journal      = {Biostatistics \& epidemiology},
	publisher    = {Taylor \& Francis},
	volume       = 5,
	number       = 2,
	pages        = {232--249}
}
@article{papernot,
	title        = {The space of transferable adversarial examples},
	author       = {Tram{\`e}r, Florian and Papernot, Nicolas and Goodfellow, Ian and Boneh, Dan and McDaniel, Patrick},
	year         = 2017,
	journal      = {arXiv:1704.03453}
}
@article{papernot_distillation_2016,
	title        = {Distillation as a {Defense} to {Adversarial} {Perturbations} against {Deep} {Neural} {Networks}},
	author       = {Papernot, Nicolas and McDaniel, Patrick and Wu, Xi and Jha, Somesh and Swami, Ananthram},
	year         = 2016,
	month        = mar,
	journal      = {arXiv:1511.04508 [cs, stat]},
	url          = {http://arxiv.org/abs/1511.04508},
	urldate      = {2020-11-03},
	abstract     = {Deep learning algorithms have been shown to perform extremely well on many classical machine learning problems. However, recent studies have shown that deep learning, like other machine learning techniques, is vulnerable to adversarial samples: inputs crafted to force a deep neural network (DNN) to provide adversary-selected outputs. Such attacks can seriously undermine the security of the system supported by the DNN, sometimes with devastating consequences. For example, autonomous vehicles can be crashed, illicit or illegal content can bypass content ﬁlters, or biometric authentication systems can be manipulated to allow improper access. In this work, we introduce a defensive mechanism called defensive distillation to reduce the effectiveness of adversarial samples on DNNs. We analytically investigate the generalizability and robustness properties granted by the use of defensive distillation when training DNNs. We also empirically study the effectiveness of our defense mechanisms on two DNNs placed in adversarial settings. The study shows that defensive distillation can reduce effectiveness of sample creation from 95\% to less than 0.5\% on a studied DNN. Such dramatic gains can be explained by the fact that distillation leads gradients used in adversarial sample creation to be reduced by a factor of 1030. We also ﬁnd that distillation increases the average minimum number of features that need to be modiﬁed to create adversarial samples by about 800\% on one of the DNNs we tested.},
	language     = {en},
	keywords     = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file         = {Papernot et al. - 2016 - Distillation as a Defense to Adversarial Perturbat.pdf:C\:\\Users\\charlie\\Zotero\\storage\\YTLSC2LI\\Papernot et al. - 2016 - Distillation as a Defense to Adversarial Perturbat.pdf:application/pdf}
}
@misc{paretoset,
	title        = {paretoset},
	author       = {tommyod},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	commit       = {9da133c}
}
@misc{Patel_Ahmad_2023,
	title        = {The inference cost of search disruption – large language model cost analysis},
	author       = {Patel, Dylan and Ahmad, Afzal},
	year         = 2023,
	month        = 2,
	journal      = {SemiAnalysis},
	publisher    = {SemiAnalysis},
	url          = {https://www.semianalysis.com/p/the-inference-cost-of-search-disruption}
}
@article{paudice_detection_2018,
	title        = {Detection of {Adversarial} {Training} {Examples} in {Poisoning} {Attacks} through {Anomaly} {Detection}},
	author       = {Paudice, Andrea and Muñoz-González, Luis and Gyorgy, Andras and Lupu, Emil C.},
	year         = 2018,
	month        = 2,
	journal      = {arXiv:1802.03041 [cs, stat]},
	url          = {http://arxiv.org/abs/1802.03041},
	urldate      = {2020-11-03},
	abstract     = {Machine learning has become an important component for many systems and applications including computer vision, spam ﬁltering, malware and network intrusion detection, among others. Despite the capabilities of machine learning algorithms to extract valuable information from data and produce accurate predictions, it has been shown that these algorithms are vulnerable to attacks. Data poisoning is one of the most relevant security threats against machine learning systems, where attackers can subvert the learning process by injecting malicious samples in the training data. Recent work in adversarial machine learning has shown that the so-called optimal attack strategies can successfully poison linear classiﬁers, degrading the performance of the system dramatically after compromising a small fraction of the training dataset. In this paper we propose a defence mechanism to mitigate the effect of these optimal poisoning attacks based on outlier detection. We show empirically that the adversarial examples generated by these attack strategies are quite different from genuine points, as no detectability constrains are considered to craft the attack. Hence, they can be detected with an appropriate pre-ﬁltering of the training dataset.},
	language     = {en},
	keywords     = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Statistics - Machine Learning},
	file         = {Paudice et al. - 2018 - Detection of Adversarial Training Examples in Pois.pdf:C\:\\Users\\charlie\\Zotero\\storage\\ABWQPGBP\\Paudice et al. - 2018 - Detection of Adversarial Training Examples in Pois.pdf:application/pdf}
}
@book{pearson2005mining,
	title        = {Mining imperfect data: Dealing with contamination and incomplete records},
	author       = {Pearson, Ronald K},
	year         = 2005,
	publisher    = {SIAM}
}
@article{pixelattack,
	title        = {Adversarial robustness assessment: Why in evaluation both $\ell_0$ and $\ell_{\infty}$ attacks are necessary},
	author       = {Kotyan, Shashank and Vargas, Danilo Vasconcellos},
	year         = 2022,
	journal      = {PloS one},
	publisher    = {Public Library of Science San Francisco, CA USA},
	volume       = 17,
	number       = 4,
	pages        = {e0265723}
}
@book{ramirez2000resource,
	title        = {A resource guide on racial profiling data collection systems: Promising practices and lessons learned},
	author       = {Ramirez, Deborah and McDevitt, Jack and Farrell, Amy},
	year         = 2000,
	publisher    = {US Department of Justice}
}
@inproceedings{resnet,
	title        = {Deep residual learning for image recognition},
	author       = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	year         = 2016,
	booktitle    = {Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages        = {770--778}
}
@article{mamba,
	title        = {An Empirical Study of Mamba-based Language Models},
	author       = {Waleffe, Roger and Byeon, Wonmin and Riach, Duncan and Norick, Brandon and Korthikanti, Vijay and Dao, Tri and Gu, Albert and Hatamizadeh, Ali and Singh, Sudhakar and Narayanan, Deepak and others},
	year         = 2024,
	journal      = {arXiv preprint arXiv:2406.07887}
}
@misc{ai_home_pricing,
	title        = {Justice Department sues RealPage for algorithmic pricing scheme that harms millions of American renters},
	author       = {United State Department of Justice},
	year         = 2025,
	month        = {2},
	journal      = {Office of Public Affairs | Justice Department Sues RealPage for Algorithmic Pricing Scheme that Harms Millions of American Renters | United States Department of Justice},
	publisher    = {United State Department of Justice},
	url          = {https://www.justice.gov/archives/opa/pr/justice-department-sues-realpage-algorithmic-pricing-scheme-harms-millions-american-renters}
}
@article{ai_power,
	year         = 2024,
	month        = may,
	journal      = {Goldman Sachs},
	url          = {https://www.goldmansachs.com/insights/articles/AI-poised-to-drive-160-increase-in-power-demand}
}

@article{mlflow,
  title={Accelerating the machine learning lifecycle with MLflow.},
  author={Zaharia, Matei and Chen, Andrew and Davidson, Aaron and Ghodsi, Ali and Hong, Sue Ann and Konwinski, Andy and Murching, Siddharth and Nykodym, Tomas and Ogilvie, Paul and Parkhe, Mani and others},
  journal={IEEE Data Eng. Bull.},
  volume={41},
  number={4},
  pages={39--45},
  year={2018}
}

@misc{ai_pipeline_regulation,
	title        = {AB-2013 Generative artificial intelligence: training data transparency.},
	author       = {{The Legislature of California}},
	year         = 2024,
	note         = {\newline\url{https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240AB2013}}
}
@misc{ai_eu_act,
	title        = {High-level summary of the AI Act},
	author       = {{The Parliament of the European Union}},
	year         = 2024,
	note         = {\newline\url{https://artificialintelligenceact.eu/high-level-summary/}}
}

@online{gdpr,
  date       = {2016-05-04},
  location   = {OJ L 119, 4.5.2016, p. 1--88},
  title      = {Regulation ({EU}) 2016/679 of the {European} {Parliament} and of the {Council}},
  url        = {https://data.europa.eu/eli/reg/2016/679/oj},
  author     = {{European Parliament} and {Council of the European Union}},
  keywords   = {access consumer data data-processing freedom gdpr information justice law personal privacy protection security verification},
  urldate    = {2025-04-13},
}
@misc{coppa,
	title        = {Children's Online Privacy Protection Act},
	author       = {{Legislature of the United States}},
	year         = 1998,
	note         = {\newline\url{https://www.govinfo.gov/content/pkg/USCODE-2011-title15/html/USCODE-2011-title15-chap91.htm}}
}
@misc{chatgptlawyer,
	title        = {New York lawyers sanctioned for using fake CHATGPT cases in legal brief | reuters},
	author       = {Merken, Sara},
	year         = 2023,
	month        = {6},
	journal      = {Reuters News},
	publisher    = {Reuters},
	url          = {https://www.reuters.com/legal/new-york-lawyers-sanctioned-using-fake-chatgpt-cases-legal-brief-2023-06-22/}
}
@inproceedings{ai_finance,
	title        = {Artificial intelligence based system for bank loan fraud prediction},
	author       = {Awotunde, Joseph Bamidele and Misra, Sanjay and Ayeni, Foluso and Maskeliunas, Rytis and Damasevicius, Robertas},
	year         = 2021,
	booktitle    = {International Conference on Hybrid Intelligent Systems},
	pages        = {463--472},
	organization = {Springer}
}
@misc{hipaa,
	title        = {Health Insurance Portability and Accountability Act},
	author       = {{Legislature of the United States}},
	year         = 1996,
	note         = {\newline\url{https://www.govinfo.gov/content/pkg/PLAW-104publ191/pdf/PLAW-104publ191.pdf}}
}
@article{ai_environment,
	title        = {Sustainable AI: AI for sustainability and the sustainability of AI},
	author       = {Van Wynsberghe, Aimee},
	year         = 2021,
	journal      = {AI and Ethics},
	publisher    = {Springer},
	volume       = 1,
	number       = 3,
	pages        = {213--218}
}
@article{ai_drones,
	title        = {Artififgfcial intelligence applied to drone control: A state of the art},
	author       = {Caballero-Martin, Daniel and Lopez-Guede, Jose Manuel and Estevez, Julian and Gra{\~n}a, Manuel},
	year         = 2024,
	journal      = {Drones},
	publisher    = {MDPI},
	volume       = 8,
	number       = 7,
	pages        = 296
}
@techreport{ISO9000,
	title        = {{SO 9001:2015 Quality management systems}},
	year         = 2015,
	month        = mar,
	address      = {Geneva, CH},
	volume       = 2015,
	type         = {Standard},
	key          = {ISO 9001:2015},
	institution  = {International Organization for Standardization},
    author = {ISO},
}

@techreport{iso2700,
	title        = {{Information security, cybersecurity and privacy protection — Information security management systems — Requirements}},
	year         = 2022,
	month        = mar,
	address      = {Geneva, CH},
	volume       = 2022,
	type         = {Standard},
	key          = {27001:2022},
	institution  = {International Organization for Standardization},
    author = {{ISO and IEC}},
}


% Tesla sleepers:
% https://www.carscoops.com/2024/04/sleeping-tesla-driver-cruised-for-25-miles-before-police-got-him-to-stop/
% https://www.nbcnews.com/news/us-news/tesla-driver-slept-car-was-going-over-80-mph-autopilot-n1267805
% https://abc7ny.com/tesla-asleep-at-wheel-sleeping-while-driving-driver-caught-snoozing/12777048/


@misc{teslasleep1, title={Sleeping tesla driver caught on Swedish Highway – after 25 miles}, url={https://www.vibilagare.se/english/sleeping-tesla-driver-caught-swedish-highway-after-25-miles}, journal={Vi Bilägare}, author={Hamelius, Simon}, year={2024}, month={4}} 

@misc{teslasleep2, title={Sleeping tesla driver caught on Swedish Highway – after 25 miles}, url={Tesla driver slept as car was going over 80 mph on Autopilot, Wisconsin officials say}, journal={National Broadcast Corporation}, author={ Tim Fitzsimons}, year={2021}, month={5}} 

@article{turingtrap,
  title={The turing trap: The promise \& peril of human-like artificial intelligence},
  author={Brynjolfsson, Erik},
  journal={Daedalus},
  volume={151},
  number={2},
  pages={272--287},
  year={2022},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{turingtestcritique1,
  title={Beyond the Turing test},
  author={Hernandez-Orallo, Jose},
  journal={Journal of Logic, Language and Information},
  volume={9},
  pages={447--466},
  year={2000},
  publisher={Springer}
}
@article{turingtest_not_metric,
  title={The Turing test is a thought experiment},
  author={Gon{\c{c}}alves, Bernardo},
  journal={Minds and Machines},
  volume={33},
  number={1},
  pages={1--31},
  year={2023},
  publisher={Springer}
}

@inproceedings{non_continuous_inversion_attack,
  title={Learning Instance-Specific Parameters of Black-Box Models Using Differentiable Surrogates},
  author={Khondaker, Arnisha and Ray, Nilanjan},
  booktitle={2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
  pages={7429--7438},
  year={2025},
  organization={IEEE}
}


@inproceedings{bekman2021practical,
  title={Practical black box model inversion attacks against neural nets},
  author={Bekman, Thomas and Abolfathi, Masoumeh and Jafarian, Haadi and Biswas, Ashis and Banaei-Kashani, Farnoush and Das, Kuntal},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={39--54},
  year={2021},
  organization={Springer}
}
@article{ai_inclusion,
  title={The limits of global inclusion in AI development},
  author={Chan, Alan and Okolo, Chinasa T and Terner, Zachary and Wang, Angelina},
  journal={arXiv preprint arXiv:2102.01265},
  year={2021}
}

@article{turingtestcritique2,
  title={Turing test: 50 years later},
  author={Pinar Saygin, Ayse and Cicekli, Ilyas and Akman, Varol},
  journal={Minds and machines},
  volume={10},
  number={4},
  pages={463--518},
  year={2000},
  publisher={Springer}
}

@article{turingtestcritique3,
  title={Evaluating ChatGPT’s consciousness and its capability to pass the Turing test: A comprehensive analysis},
  author={Gams, Matjaz and Kramar, Sebastjan},
  journal={Journal of Computer and Communications},
  volume={12},
  number={3},
  pages={219--237},
  year={2024},
  publisher={Scientific Research Publishing}
}


@misc{teslasleep3, title={Caught on video: Tesla driver apparently asleep at the wheel on California freeway}, url={https://abc7ny.com/tesla-asleep-at-wheel-sleeping-while-driving-driver-caught-snoozing/12777048/}, journal={American Broadcast Corporation}, author={KABC}, year={2023}, month={2}} 

@article{mou2019artificial,
	title        = {Artificial intelligence: investment trends and selected industry uses},
	author       = {Mou, Xiaomin},
	year         = 2019,
	journal      = {International Finance Corporation},
	volume       = 8,
	number       = 2,
	pages        = {311--320}
}
@article{ai_translation,
	title        = {The impact of artificial intelligence on language translation: a review},
	author       = {Mohamed, Yasir Abdelgadir and Khanan, Akbar and Bashir, Mohamed and Mohamed, Abdul Hakim HM and Adiel, Mousab AE and Elsadig, Muawia A},
	year         = 2024,
	journal      = {Ieee Access},
	publisher    = {IEEE},
	volume       = 12,
	pages        = {25553--25579}
}
@article{shiffman2012nature,
	title        = {The nature of code},
	author       = {Shiffman, Daniel},
	year         = 2012,
	journal      = {(No Title)}
}
@misc{summervision,
	title        = {The summer vision project},
	author       = {Papert, Seymour A.},
	year         = 1966,
	month        = {7},
	journal      = {The Summer Vision Project},
	publisher    = {Massachusetts Institute of Technology},
	url          = {https://dspace.mit.edu/handle/1721.1/6125}
}
@book{hofstadter1999godel,
	title        = {G{\"o}del, Escher, Bach: an eternal golden braid},
	author       = {Hofstadter, Douglas R},
	year         = 1999,
	publisher    = {Basic books}
}
@phdthesis{phillips1999if,
	title        = {If it works, it's not AI: a commercial look at artificial intelligence startups},
	author       = {Phillips, Eve Marie},
	year         = 1999,
	school       = {Massachusetts Institute of Technology}
}
@article{reverse_sigmoid,
	title        = {Defending Against Model Stealing Attacks Using Deceptive Perturbations},
	author       = {Taesung Lee and Benjamin Edwards and Ian M. Molloy and Dong Su},
	year         = 2018,
	journal      = {CoRR},
	volume       = {abs/1806.00054},
	url          = {http://arxiv.org/abs/1806.00054},
	eprinttype   = {arXiv},
	eprint       = {1806.00054},
	timestamp    = {Wed, 02 Jun 2021 09:13:29 +0200},
	biburl       = {https://dblp.org/rec/journals/corr/abs-1806-00054.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{roh2019survey,
	title        = {A survey on data collection for machine learning: a big data-ai integration perspective},
	author       = {Roh, Yuji and Heo, Geon and Whang, Steven Euijong},
	year         = 2019,
	journal      = {IEEE Transactions on Knowledge and Data Engineering},
	publisher    = {IEEE},
	volume       = 33,
	number       = 4,
	pages        = {1328--1347}
}
@article{rolnick2017power,
	title        = {The power of deeper networks for expressing natural functions},
	author       = {Rolnick, David and Tegmark, Max},
	year         = 2017,
	journal      = {arXiv preprint arXiv:1705.05502}
}
@inproceedings{ross2018improving,
	title        = {Improving the adversarial robustness and interpretability of deep neural networks by regularizing their input gradients},
	author       = {Ross, Andrew and Doshi-Velez, Finale},
	year         = 2018,
	booktitle    = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume       = 32
}
@inproceedings{ruan2019global,
	title        = {Global robustness evaluation of deep neural networks with provable guarantees for the hamming distance},
	author       = {Ruan, Wenjie and Wu, Min and Sun, Youcheng and Huang, Xiaowei and Kroening, Daniel and Kwiatkowska, Marta},
	year         = 2019,
	organization = {IJCAI}
}
@article{rudin1992nonlinear,
	title        = {Nonlinear total variation based noise removal algorithms},
	author       = {Rudin, Leonid I and Osher, Stanley and Fatemi, Emad},
	year         = 1992,
	journal      = {Physica D: nonlinear phenomena},
	publisher    = {Elsevier},
	volume       = 60,
	number       = {1-4},
	pages        = {259--268}
}
@article{safetyframework,
	title        = {A framework for safety automation of safety-critical systems operations},
	author       = {Acharyulu, PV Srinivas and Seetharamaiah, P},
	year         = 2015,
	journal      = {Safety Science},
	publisher    = {Elsevier},
	volume       = 77,
	pages        = {133--142}
}
@inproceedings{saha2020hidden,
	title        = {Hidden trigger backdoor attacks},
	author       = {Saha, Aniruddha and Subramanya, Akshayvarun and Pirsiavash, Hamed},
	year         = 2020,
	booktitle    = {Proceedings of the AAAI conference on artificial intelligence},
	volume       = 34,
	number       = {07},
	pages        = {11957--11965}
}
@article{sahiner2019deep,
	title        = {Deep learning in medical imaging and radiation therapy},
	author       = {Sahiner, Berkman and Pezeshk, Aria and Hadjiiski, Lubomir M and Wang, Xiaosong and Drukker, Karen and Cha, Kenny H and Summers, Ronald M and Giger, Maryellen L},
	year         = 2019,
	journal      = {Medical physics},
	publisher    = {Wiley Online Library},
	volume       = 46,
	number       = 1,
	pages        = {e1--e36}
}
@inproceedings{sajid2013cloud,
	title        = {Cloud computing: Issues \& challenges},
	author       = {Sajid, Mohammad and Raza, Zahid},
	year         = 2013,
	booktitle    = {International conference on cloud, big data and trust},
	volume       = 20,
	number       = 13,
	pages        = {13--15},
	organization = {sn}
}
@article{santos2021universal,
	title        = {Universal adversarial attacks on neural networks for power allocation in a massive MIMO system},
	author       = {Santos, Pablo Mill{\'a}n and Manoj, BR and Sadeghi, Meysam and Larsson, Erik G},
	year         = 2021,
	journal      = {IEEE Wireless Communications Letters},
	publisher    = {IEEE},
	volume       = 11,
	number       = 1,
	pages        = {67--71}
}
@article{schmoor2000sample,
	title        = {Sample size considerations for the evaluation of prognostic factors in survival analysis},
	author       = {Schmoor, Claudia and Sauerbrei, Willi and Schumacher, Martin},
	year         = 2000,
	journal      = {Statistics in medicine},
	publisher    = {Wiley Online Library},
	volume       = 19,
	number       = 4,
	pages        = {441--452}
}
@inproceedings{sedghpour@ebpf,
	title        = {Service Mesh and eBPF-Powered Microservices: A Survey and Future Directions},
	author       = {Sedghpour, Mohammad Reza Saleh and Townend, Paul},
	year         = 2022,
	booktitle    = {2022 IEEE International Conference on Service-Oriented System Engineering (SOSE)},
	pages        = {176--184},
	doi          = {10.1109/SOSE55356.2022.00027}
}
@article{sehwag2019towards,
	title        = {Towards compact and robust deep neural networks},
	author       = {Sehwag, Vikash and Wang, Shiqi and Mittal, Prateek and Jana, Suman},
	year         = 2019,
	journal      = {arXiv:1906.06110}
}
@book{shalev2014understanding,
	title        = {Understanding machine learning: From theory to algorithms},
	author       = {Shalev-Shwartz, Shai and Ben-David, Shai},
	year         = 2014,
	publisher    = {Cambridge university press, Cambridge, UK.}
}
@article{alom2018history,
	title        = {The history began from alexnet: A comprehensive survey on deep learning approaches},
	author       = {Alom, Md Zahangir and Taha, Tarek M and Yakopcic, Christopher and Westberg, Stefan and Sidike, Paheding and Nasrin, Mst Shamima and Van Esesn, Brian C and Awwal, Abdul A S and Asari, Vijayan K},
	year         = 2018,
	journal      = {arXiv preprint arXiv:1803.01164}
}
@inproceedings{shokri2017membership,
	title        = {Membership inference attacks against machine learning models},
	author       = {Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly},
	year         = 2017,
	booktitle    = {2017 IEEE Symposium on Security and Privacy (SP)},
	pages        = {3--18},
	organization = {IEEE}
}
@article{simon-gabriel_first-order_2019,
	title        = {First-order {Adversarial} {Vulnerability} of {Neural} {Networks} and {Input} {Dimension}},
	author       = {Simon-Gabriel, Carl-Johann and Ollivier, Yann and Bottou, Léon and Schölkopf, Bernhard and Lopez-Paz, David},
	year         = 2019,
	month        = jun,
	journal      = {arXiv:1802.01421 [cs, stat]},
	url          = {http://arxiv.org/abs/1802.01421},
	urldate      = {2020-09-17},
	abstract     = {Over the past few years, neural networks were proven vulnerable to adversarial images: targeted but imperceptible image perturbations lead to drastically different predictions. We show that adversarial vulnerability increases with the gradients of the training objective when viewed as a function of the inputs. Surprisingly, vulnerability does not depend on network topology: for many standard network architectures, we prove that at initialization, the 1-norm of these gradients grows as the square root of the input dimension, leaving the networks increasingly vulnerable with growing image size. We empirically show that this dimension dependence persists after either usual or robust training, but gets attenuated with higher regularization.},
	language     = {en},
	keywords     = {68T45, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, I.2.6, Statistics - Machine Learning},
	file         = {Simon-Gabriel et al. - 2019 - First-order Adversarial Vulnerability of Neural Ne.pdf:C\:\\Users\\charlie\\Zotero\\storage\\HNKCWFZ8\\Simon-Gabriel et al. - 2019 - First-order Adversarial Vulnerability of Neural Ne.pdf:application/pdf}
}
@article{singh2023load,
	title        = {Load balancing and service discovery using Docker Swarm for microservice based big data applications},
	author       = {Singh, Neelam and Hamid, Yasir and Juneja, Sapna and Srivastava, Gautam and Dhiman, Gaurav and Gadekallu, Thippa Reddy and Shah, Mohd Asif},
	year         = 2023,
	journal      = {Journal of Cloud Computing},
	publisher    = {Springer},
	volume       = 12,
	number       = 1,
	pages        = 4
}
@inproceedings{sinn2019evolutionary,
	title        = {Evolutionary search for adversarially robust neural networks},
	author       = {Sinn, Mathieu and Wistuba, M and Buesser, B and Nicolae, MI and Tran, M},
	year         = 2019,
	booktitle    = {Safe Machine Learning workshop at ICLR}
}
@inproceedings{smith2019super,
	title        = {Super-convergence: Very fast training of neural networks using large learning rates},
	author       = {Smith, Leslie N and Topin, Nicholay},
	year         = 2019,
	booktitle    = {Artificial intelligence and machine learning for multi-domain operations applications},
	volume       = 11006,
	pages        = {369--386},
	organization = {SPIE}
}
@book{stats,
	title        = {An introduction to mathematical statistics and its applications},
	author       = {Larsen, Richard J. and Marx, Morris L.},
	year         = 2018,
	publisher    = {Pearson},
	place        = {Boston}
}
@article{stoica2004model,
	title        = {Model-order selection: a review of information criterion rules},
	author       = {Stoica, Petre and Selen, Yngve},
	year         = 2004,
	journal      = {IEEE Signal Processing Magazine},
	publisher    = {IEEE},
	volume       = 21,
	number       = 4,
	pages        = {36--47}
}
@inproceedings{sun2017revisiting,
	title        = {Revisiting unreasonable effectiveness of data in deep learning era},
	author       = {Sun, Chen and Shrivastava, Abhinav and Singh, Saurabh and Gupta, Abhinav},
	year         = 2017,
	booktitle    = {Proceedings of the IEEE international conference on computer vision},
	pages        = {843--852}
}
@inproceedings{svedin2021benchmarking,
	title        = {Benchmarking the nvidia gpu lineage: From early k80 to modern a100 with asynchronous memory transfers},
	author       = {Svedin, Martin and Chien, Steven WD and Chikafa, Gibson and Jansson, Niclas and Podobas, Artur},
	year         = 2021,
	booktitle    = {Proceedings of the 11th International Symposium on Highly Efficient Accelerators and Reconfigurable Technologies},
	pages        = {1--6}
}
@book{taddy2019business,
	title        = {Business data science: Combining machine learning and economics to optimize, automate, and accelerate business decisions},
	author       = {Taddy, Matt},
	year         = 2019,
	publisher    = {McGraw-Hill Education}
}
@article{tan2021critical,
	title        = {A critical look at the current train/test split in machine learning},
	author       = {Tan, Jimin and Yang, Jianan and Wu, Sai and Chen, Gang and Zhao, Jake},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2106.04525}
}
@inproceedings{testautomation,
	title        = {Test automation for safety-critical systems: Industrial application and future developments},
	author       = {Peleska, Jan},
	year         = 1996,
	booktitle    = {International Symposium of Formal Methods Europe},
	pages        = {39--59},
	organization = {Springer}
}
@inproceedings{thill_online_2017,
	title        = {Online anomaly detection on the webscope {S5} dataset: {A} comparative study},
	shorttitle   = {Online anomaly detection on the webscope {S5} dataset},
	author       = {Thill, M. and Konen, W. and Bäck, T.},
	year         = 2017,
	month        = may,
	booktitle    = {2017 {Evolving} and {Adaptive} {Intelligent} {Systems} ({EAIS})},
	pages        = {1--8},
	doi          = {10.1109/EAIS.2017.7954844},
	note         = {ISSN: 2473-4691},
	abstract     = {An unresolved challenge for all kind of temporal data is the reliable anomaly detection, especially when adaptability is required in the case of non-stationary time series or when the nature of future anomalies is unknown or only vaguely defined. Most of the current anomaly detection algorithms follow the general idea to classify an anomaly as a significant deviation from the prediction. In this paper we present a comparative study where several online anomaly detection algorithms are compared on the large Yahoo Webscope S5 anomaly benchmark. We show that a relatively Simple Online Regression Anomaly Detector (SORAD) is quite successful compared to other anomaly detectors. We discuss the importance of several adaptive and online elements of the algorithm and their influence on the overall anomaly detection accuracy.},
	keywords     = {Benchmark testing, data handling, Detection algorithms, Internet, nonstationary time series, online anomaly detection, Prediction algorithms, regression analysis, simple online regression anomaly detector, SORAD, temporal data, time series, Time series analysis, Training, Training data, Transient analysis, Yahoo Webscope S5 anomaly benchmark}
}
@inproceedings{thill_online_2017-1,
	title        = {Online anomaly detection on the webscope {S5} dataset: {A} comparative study},
	shorttitle   = {Online anomaly detection on the webscope {S5} dataset},
	author       = {Thill, M. and Konen, W. and Bäck, T.},
	year         = 2017,
	month        = may,
	booktitle    = {2017 {Evolving} and {Adaptive} {Intelligent} {Systems} ({EAIS})},
	pages        = {1--8},
	doi          = {10.1109/EAIS.2017.7954844},
	note         = {ISSN: 2473-4691},
	abstract     = {An unresolved challenge for all kind of temporal data is the reliable anomaly detection, especially when adaptability is required in the case of non-stationary time series or when the nature of future anomalies is unknown or only vaguely defined. Most of the current anomaly detection algorithms follow the general idea to classify an anomaly as a significant deviation from the prediction. In this paper we present a comparative study where several online anomaly detection algorithms are compared on the large Yahoo Webscope S5 anomaly benchmark. We show that a relatively Simple Online Regression Anomaly Detector (SORAD) is quite successful compared to other anomaly detectors. We discuss the importance of several adaptive and online elements of the algorithm and their influence on the overall anomaly detection accuracy.},
	keywords     = {Benchmark testing, data handling, Detection algorithms, Internet, nonstationary time series, online anomaly detection, Prediction algorithms, regression analysis, simple online regression anomaly detector, SORAD, temporal data, time series, Time series analysis, Training, Training data, Transient analysis, Yahoo Webscope S5 anomaly benchmark},
	file         = {IEEE Xplore Abstract Record:C\:\\Users\\charlie\\Zotero\\storage\\VBVMH5UI\\7954844.html:text/html}
}
@article{tiwari_binary_2019,
	title        = {Binary {Classifier} {Inspired} by {Quantum} {Theory}},
	author       = {Tiwari, Prayag and Melucci, Massimo},
	year         = 2019,
	month        = jul,
	journal      = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume       = 33,
	number       = {01},
	pages        = {10051--10052},
	doi          = {10.1609/aaai.v33i01.330110051},
	issn         = {2374-3468},
	url          = {https://www.aaai.org/ojs/index.php/AAAI/article/view/5162},
	urldate      = {2020-11-02},
	copyright    = {Copyright (c) 2019 Association for the Advancement of Artificial Intelligence},
	note         = {Number: 01},
	abstract     = {Machine Learning (ML) helps us to recognize patterns from raw data. ML is used in numerous domains i.e. biomedical, agricultural, food technology, etc. Despite recent technological advancements, there is still room for substantial improvement in prediction. Current ML models are based on classical theories of probability and statistics, which can now be replaced by Quantum Theory (QT) with the aim of improving the effectiveness of ML. In this paper, we propose the Binary Classifier Inspired by Quantum Theory (BCIQT) model, which outperforms the state of the art classification in terms of recall for every category.},
	language     = {en},
	file         = {Full Text PDF:C\:\\Users\\charlie\\Zotero\\storage\\U2PBJDV3\\Tiwari and Melucci - 2019 - Binary Classifier Inspired by Quantum Theory.pdf:application/pdf;Snapshot:C\:\\Users\\charlie\\Zotero\\storage\\K7AHN2DJ\\5162.html:text/html}
}
@book{topologytextbook,
	title        = {Introduction to topology},
	author       = {Mendelson, Bert},
	year         = 2012,
	publisher    = {Dover Publications},
	place        = {New York}
}
@article{tramer,
	title        = {The space of transferable adversarial examples},
	author       = {Tram{\`e}r, Florian and Papernot, Nicolas and Goodfellow, Ian and Boneh, Dan and McDaniel, Patrick},
	year         = 2017,
	journal      = {arXiv:1704.03453}
}
@article{tramer_stealing_nodate,
	title        = {Stealing {Machine} {Learning} {Models} via {Prediction} {APIs}},
	author       = {Tramer, Florian and Zhang, Fan and Juels, Ari and Reiter, Michael K and Ristenpart, Thomas},
	pages        = 19,
	abstract     = {Machine learning (ML) models may be deemed confidential due to their sensitive training data, commercial value, or use in security applications. Increasingly often, confidential ML models are being deployed with publicly accessible query interfaces. ML-as-a-service (“predictive analytics”) systems are an example: Some allow users to train models on potentially sensitive data and charge others for access on a pay-per-query basis.},
	language     = {en},
	file         = {Tramer et al. - Stealing Machine Learning Models via Prediction AP.pdf:C\:\\Users\\charlie\\Zotero\\storage\\Q4ZJNER6\\Tramer et al. - Stealing Machine Learning Models via Prediction AP.pdf:application/pdf}
}


@misc{tensorflow,
title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
note={Software available from tensorflow.org},
author={
    Mart\'{i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dandelion~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015},
}


@article{sklearn,
  title={Scikit-learn: Machine Learning in {P}ython},
  author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
          and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
          and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
          Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  journal={Journal of Machine Learning Research},
  volume={12},
  pages={2825--2830},
  year={2011}
}
@inproceedings{tramer2016stealing,
	title        = {Stealing machine learning models via prediction {API}s},
	author       = {Tram{\`e}r, Florian and Zhang, Fan and Juels, Ari and Reiter, Michael K and Ristenpart, Thomas},
	year         = 2016,
	booktitle    = {25th {USENIX} Security Symposium ({USENIX} Security 16)},
	pages        = {601--618}
}

@article{pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library. arXiv 2019},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={arXiv preprint arXiv:1912.01703},
  volume={10},
  year={1912}
}

@article{tsipras_robustness_2019,
	title        = {Robustness {May} {Be} at {Odds} with {Accuracy}},
	author       = {Tsipras, Dimitris and Santurkar, Shibani and Engstrom, Logan and Turner, Alexander and Madry, Aleksander},
	year         = 2019,
	month        = sep,
	journal      = {arXiv:1805.12152 [cs, stat]},
	url          = {http://arxiv.org/abs/1805.12152},
	urldate      = {2020-10-01},
	abstract     = {We show that there may exist an inherent tension between the goal of adversarial robustness and that of standard generalization. Speciﬁcally, training robust models may not only be more resource-consuming, but also lead to a reduction of standard accuracy. We demonstrate that this trade-off between the standard accuracy of a model and its robustness to adversarial perturbations provably exists in a fairly simple and natural setting. These ﬁndings also corroborate a similar phenomenon observed empirically in more complex settings. Further, we argue that this phenomenon is a consequence of robust classiﬁers learning fundamentally different feature representations than standard classiﬁers. These differences, in particular, seem to result in unexpected beneﬁts: the representations learned by robust models tend to align better with salient data characteristics and human perception.},
	language     = {en},
	keywords     = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
	file         = {Tsipras et al. - 2019 - Robustness May Be at Odds with Accuracy.pdf:C\:\\Users\\charlie\\Zotero\\storage\\2V7GJHIL\\Tsipras et al. - 2019 - Robustness May Be at Odds with Accuracy.pdf:application/pdf}
}
@inproceedings{tuan2010modeling,
	title        = {Modeling and verification of safety critical systems: A case study on pacemaker},
	author       = {Tuan, Luu Anh and Zheng, Man Chun and Tho, Quan Thanh},
	year         = 2010,
	booktitle    = {2010 Fourth International Conference on Secure Software Integration and Reliability Improvement},
	pages        = {23--32},
	organization = {IEEE}
}
@article{uesato_adversarial_2018,
	title        = {Adversarial {Risk} and the {Dangers} of {Evaluating} {Against} {Weak} {Attacks}},
	author       = {Uesato, Jonathan and O'Donoghue, Brendan and Oord, Aaron van den and Kohli, Pushmeet},
	year         = 2018,
	month        = jun,
	journal      = {arXiv:1802.05666 [cs, stat]},
	url          = {http://arxiv.org/abs/1802.05666},
	urldate      = {2020-09-28},
	abstract     = {This paper investigates recently proposed approaches for defending against adversarial examples and evaluating adversarial robustness. We motivate adversarial risk as an objective for achieving models robust to worst-case inputs. We then frame commonly used attacks and evaluation metrics as deﬁning a tractable surrogate objective to the true adversarial risk. This suggests that models may optimize this surrogate rather than the true adversarial risk. We formalize this notion as obscurity to an adversary, and develop tools and heuristics for identifying obscured models and designing transparent models. We demonstrate that this is a signiﬁcant problem in practice by repurposing gradient-free optimization techniques into adversarial attacks, which we use to decrease the accuracy of several recently proposed defenses to near zero. Our hope is that our formulations and results will help researchers to develop more powerful defenses.},
	language     = {en},
	keywords     = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Statistics - Machine Learning},
	file         = {Uesato et al. - 2018 - Adversarial Risk and the Dangers of Evaluating Aga.pdf:C\:\\Users\\charlie\\Zotero\\storage\\V4RNGWRE\\Uesato et al. - 2018 - Adversarial Risk and the Dangers of Evaluating Aga.pdf:application/pdf}
}
@article{vadera_assessing_2020,
	title        = {Assessing the {Adversarial} {Robustness} of {Monte} {Carlo} and {Distillation} {Methods} for {Deep} {Bayesian} {Neural} {Network} {Classification}},
	author       = {Vadera, Meet P. and Shukla, Satya Narayan and Jalaian, Brian and Marlin, Benjamin M.},
	year         = 2020,
	month        = 2,
	journal      = {arXiv:2002.02842 [cs, stat]},
	url          = {http://arxiv.org/abs/2002.02842},
	urldate      = {2020-07-20},
	abstract     = {In this paper, we consider the problem of assessing the adversarial robustness of deep neural network models under both Markov chain Monte Carlo (MCMC) and Bayesian Dark Knowledge (BDK) inference approximations. We characterize the robustness of each method to two types of adversarial attacks: the fast gradient sign method (FGSM) and projected gradient descent (PGD). We show that full MCMC-based inference has excellent robustness, signiﬁcantly outperforming standard point estimation-based learning. On the other hand, BDK provides marginal improvements. As an additional contribution, we present a storage-efﬁcient approach to computing adversarial examples for large Monte Carlo ensembles using both the FGSM and PGD attacks.},
	language     = {en},
	keywords     = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file         = {2002.02842[1].pdf:C\:\\Users\\charlie\\AppData\\Local\\Microsoft\\Windows\\INetCache\\IE\\M03SCMDN\\2002.02842[1].pdf:application/pdf}
}
@article{vapnik1994measuring,
	title        = {Measuring the VC-dimension of a learning machine},
	author       = {Vapnik, Vladimir and Levin, Esther and Le Cun, Yann},
	year         = 1994,
	journal      = {Neural computation},
	publisher    = {MIT Press},
	volume       = 6,
	number       = 5,
	pages        = {851--876}
}
@article{vcdimension,
	title        = {An overview of statistical learning theory},
	author       = {Vapnik, Vladimir N},
	year         = 1999,
	journal      = {IEEE transactions on neural networks},
	publisher    = {IEEE},
	volume       = 10,
	number       = 5,
	pages        = {988--999}
}
@inproceedings{vehicle_formal,
	title        = {Formal scenario-based testing of autonomous vehicles: From simulation to the real world},
	author       = {Fremont, Daniel J and Kim, Edward and Pant, Yash Vardhan and Seshia, Sanjit A and Acharya, Atul and Bruso, Xantha and Wells, Paul and Lemke, Steve and Lu, Qiang and Mehta, Shalin},
	year         = 2020,
	booktitle    = {2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC)},
	pages        = {1--8},
	organization = {IEEE}
}
@inproceedings{vehicle_testing_review,
	title        = {Autonomous vehicles testing methods review},
	author       = {Huang, WuLing and Wang, Kunfeng and Lv, Yisheng and Zhu, FengHua},
	year         = 2016,
	booktitle    = {2016 IEEE 19th International Conference on Intelligent Transportation Systems (ITSC)},
	pages        = {163--168},
	organization = {IEEE}
}
@article{wang_security_2019,
	title        = {The security of machine learning in an adversarial setting: {A} survey},
	shorttitle   = {The security of machine learning in an adversarial setting},
	author       = {Wang, Xianmin and Li, Jing and Kuang, Xiaohui and Tan, Yu-an and Li, Jin},
	year         = 2019,
	month        = aug,
	journal      = {Journal of Parallel and Distributed Computing},
	volume       = 130,
	pages        = {12--23},
	doi          = {10.1016/j.jpdc.2019.03.003},
	issn         = {07437315},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0743731518309183},
	urldate      = {2020-08-12},
	abstract     = {Machine learning (ML) methods have demonstrated impressive performance in many application fields such as autopilot, facial recognition, and spam detection. Traditionally, ML models are trained and deployed in a benign setting, in which the testing and training data have identical statistical characteristics. However, this assumption usually does not hold in the sense that the ML model is designed in an adversarial setting, where some statistical properties of the data can be tampered with by a capable adversary. Specifically, it has been observed that adversarial examples (also known as adversarial input perambulations) elaborately crafted during training/test phases can seriously undermine the ML performance. The susceptibility of ML models in adversarial settings and the corresponding countermeasures have been studied by many researchers in both academic and industrial communities. In this work, we present a comprehensive overview of the investigation of the security properties of ML algorithms under adversarial settings. First, we analyze the ML security model to develop a blueprint for this interdisciplinary research area. Then, we review adversarial attack methods and discuss the defense strategies against them. Finally, relying upon the reviewed work, we provide prospective relevant future works for designing more secure ML models.},
	language     = {en},
	file         = {Wang et al. - 2019 - The security of machine learning in an adversarial.pdf:C\:\\Users\\charlie\\Zotero\\storage\\IZAB3YMW\\Wang et al. - 2019 - The security of machine learning in an adversarial.pdf:application/pdf}
}
@article{wang2019benchmarking,
	title        = {Benchmarking TPU, GPU, and CPU platforms for deep learning},
	author       = {Wang, Yu Emma and Wei, Gu-Yeon and Brooks, David},
	year         = 2019,
	journal      = {arXiv preprint arXiv:1907.10701}
}
@inproceedings{xiao2021improving,
	title        = {Improving Transferability of Adversarial Patches on Face Recognition With Generative Models},
	author       = {Xiao, Zihao and Gao, Xianfeng and Fu, Chilin and Dong, Yinpeng and Gao, Wei and Zhang, Xiaolu and Zhou, Jun and Zhu, Jun},
	year         = 2021,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {11845--11854}
}
@inproceedings{xu2018deep,
	title        = {Deep learning at scale on nvidia v100 accelerators},
	author       = {Xu, Rengan and Han, Frank and Ta, Quy},
	year         = 2018,
	booktitle    = {2018 IEEE/ACM Performance Modeling, Benchmarking and Simulation of High Performance Computer Systems (PMBS)},
	pages        = {23--32},
	organization = {IEEE}
}
@article{yu_bayesian_2016,
	title        = {A {Bayesian} {Ensemble} for {Unsupervised} {Anomaly} {Detection}},
	author       = {Yu, Edward and Parekh, Parth},
	year         = 2016,
	month        = oct,
	journal      = {arXiv:1610.07677 [cs, stat]},
	url          = {http://arxiv.org/abs/1610.07677},
	urldate      = {2020-07-20},
	abstract     = {Methods for unsupervised anomaly detection suﬀer from the fact that the data is unlabeled, making it diﬃcult to assess the optimality of detection algorithms. Ensemble learning has shown exceptional results in classiﬁcation and clustering problems, but has not seen as much research in the context of outlier detection. Existing methods focus on combining output scores of individual detectors, but this leads to outputs that are not easily interpretable. In this paper, we introduce a theoretical foundation for combining individual detectors with Bayesian classiﬁer combination. Not only are posterior distributions easily interpreted as the probability distribution of anomalies, but bias, variance, and individual error rates of detectors are all easily obtained. Performance on real-world datasets shows high accuracy across varied types of time series data.},
	language     = {en},
	keywords     = {Computer Science - Machine Learning, Statistics - Machine Learning}
}
@inproceedings{zhang_cross-dataset_2019,
	title        = {Cross-dataset time series anomaly detection for cloud systems},
	author       = {Zhang, Xu and Lin, Qingwei and Xu, Yong and Qin, Si and Zhang, Hongyu and Qiao, Bo and Dang, Yingnong and Yang, Xinsheng and Cheng, Qian and Chintalapati, Murali and Wu, Youjiang and Hsieh, Ken and Sui, Kaixin and Meng, Xin and Xu, Yaohai and Zhang, Wenchi and Shen, Furao and Zhang, Dongmei},
	year         = 2019,
	month        = jul,
	booktitle    = {Proceedings of the 2019 {USENIX} {Conference} on {Usenix} {Annual} {Technical} {Conference}},
	publisher    = {USENIX Association},
	address      = {USA},
	series       = {{USENIX} {ATC} '19},
	pages        = {1063--1076},
	isbn         = {978-1-939133-03-8},
	urldate      = {2020-11-02},
	abstract     = {In recent years, software applications are increasingly deployed as online services on cloud computing platforms. It is important to detect anomalies in cloud systems in order to maintain high service availability. However, given the velocity, volume, and diversified nature of cloud monitoring data, it is difficult to obtain sufficient labelled data to build an accurate anomaly detection model. In this paper, we propose cross-dataset anomaly detection: detect anomalies in a new unlabelled dataset (the target) by training an anomaly detection model on existing labelled datasets (the source). Our approach, called ATAD (Active Transfer Anomaly Detection), integrates both transfer learning and active learning techniques. Transfer learning is applied to transfer knowledge from the source dataset to the target dataset, and active learning is applied to determine informative labels of a small part of samples from unlabelled datasets. Through experiments, we show that ATAD is effective in cross-dataset time series anomaly detection. Furthermore, we only need to label about 1\%-5\% of unlabelled data and can still achieve significant performance improvement.}
}
@article{zhou2022online,
	title        = {Online scheduling algorithm for heterogeneous distributed machine learning jobs},
	author       = {Zhou, Ruiting and Pang, Jinlong and Zhang, Qin and Wu, Chuan and Jiao, Lei and Zhong, Yi and Li, Zongpeng},
	year         = 2022,
	journal      = {IEEE Transactions on Cloud Computing},
	publisher    = {IEEE}
}
@article{ziai_active_2019,
	title        = {Active {Learning} for {Network} {Intrusion} {Detection}},
	author       = {Ziai, Amir},
	year         = 2019,
	month        = apr,
	journal      = {arXiv:1904.01555 [cs, stat]},
	url          = {http://arxiv.org/abs/1904.01555},
	urldate      = {2020-11-02},
	abstract     = {Network operators are generally aware of common attack vectors that they defend against. For most networks the vast majority of traffic is legitimate. However new attack vectors are continually designed and attempted by bad actors which bypass detection and go unnoticed due to low volume. One strategy for finding such activity is to look for anomalous behavior. Investigating anomalous behavior requires significant time and resources. Collecting a large number of labeled examples for training supervised models is both prohibitively expensive and subject to obsoletion as new attacks surface. A purely unsupervised methodology is ideal; however, research has shown that even a very small number of labeled examples can significantly improve the quality of anomaly detection. A methodology that minimizes the number of required labels while maximizing the quality of detection is desirable. False positives in this context result in wasted effort or blockage of legitimate traffic and false negatives translate to undetected attacks. We propose a general active learning framework and experiment with different choices of learners and sampling strategies.},
	keywords     = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Statistics - Machine Learning},
	file         = {arXiv Fulltext PDF:C\:\\Users\\charlie\\Zotero\\storage\\I6PUG64G\\Ziai - 2019 - Active Learning for Network Intrusion Detection.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\charlie\\Zotero\\storage\\MPS8FFA3\\1904.html:text/html}
}

@inproceedings{ray,
  title={Ray: A distributed framework for emerging $\{$AI$\}$ applications},
  author={Moritz, Philipp and Nishihara, Robert and Wang, Stephanie and Tumanov, Alexey and Liaw, Richard and Liang, Eric and Elibol, Melih and Yang, Zongheng and Paul, William and Jordan, Michael I and others},
  booktitle={13th USENIX symposium on operating systems design and implementation (OSDI 18)},
  pages={561--577},
  year={2018}
}

@article{nevergrad,
  title={Nevergrad: black-box optimization platform},
  author={Bennet, Pauline and Doerr, Carola and Moreau, Antoine and Rapin, Jeremy and Teytaud, Fabien and Teytaud, Olivier},
  journal={ACM SIGEVOlution},
  volume={14},
  number={1},
  pages={8--15},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{art,
  title={Adversarial Robustness Toolbox v1. 0.0},
  author={Nicolae, Maria-Irina and Sinn, Mathieu and Tran, Minh Ngoc and Buesser, Beat and Rawat, Ambrish and Wistuba, Martin and Zantedeschi, Valentina and Baracaldo, Nathalie and Chen, Bryant and Ludwig, Heiko and others},
  journal={arXiv preprint arXiv:1807.01069},
  year={2018}
}

@inproceedings{ghosh2019resisting,
	title        = {Resisting adversarial attacks using gaussian mixture variational autoencoders},
	author       = {Ghosh, Partha and Losalka, Arpan and Black, Michael J},
	year         = 2019,
	booktitle    = {Proceedings of the AAAI conference on artificial intelligence},
	volume       = 33,
	number       = {01},
	pages        = {541--548}
}
@article{zirger1996effect,
	title        = {The effect of acceleration techniques on product development time},
	author       = {Zirger, Billie J and Hartley, Janet L},
	year         = 1996,
	journal      = {IEEE Transactions on Engineering Management},
	publisher    = {IEEE},
	volume       = 43,
	number       = 2,
	pages        = {143--152}
}
@article{zitzler2008quality,
	title        = {Quality assessment of pareto set approximations},
	author       = {Zitzler, Eckart and Knowles, Joshua and Thiele, Lothar},
	year         = 2008,
	journal      = {Multiobjective optimization: Interactive and evolutionary approaches},
	publisher    = {Springer},
	pages        = {373--404}
}
@inproceedings{ben2020adversarial,
	title        = {The adversarial robustness of sampling},
	author       = {Ben-Eliezer, Omri and Yogev, Eylon},
	year         = 2020,
	booktitle    = {Proceedings of the 39th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems},
	pages        = {49--62}
}
@article{christmann2004robustness,
	title        = {On robustness properties of convex risk minimization methods for pattern recognition},
	author       = {Christmann, Andreas and Steinwart, Ingo},
	year         = 2004,
	journal      = {The Journal of Machine Learning Research},
	publisher    = {JMLR. org},
	volume       = 5,
	pages        = {1007--1034}
}
@article{yarger2020algorithmic,
	title        = {Algorithmic equity in the hiring of underrepresented IT job candidates},
	author       = {Yarger, Lynette and Cobb Payton, Fay and Neupane, Bikalpa},
	year         = 2020,
	journal      = {Online information review},
	publisher    = {Emerald Publishing Limited},
	volume       = 44,
	number       = 2,
	pages        = {383--395}
}
@article{rattan2019identical,
	title        = {Identical applicant but different outcomes: The impact of gender versus race salience in hiring},
	author       = {Rattan, Aneeta and Steele, Jennifer and Ambady, Nalini},
	year         = 2019,
	journal      = {Group Processes \& Intergroup Relations},
	publisher    = {Sage Publications Sage UK: London, England},
	volume       = 22,
	number       = 1,
	pages        = {80--97}
}
@article{birhane2021algorithmic,
	title        = {Algorithmic injustice: a relational ethics approach},
	author       = {Birhane, Abeba},
	year         = 2021,
	journal      = {Patterns},
	publisher    = {Elsevier},
	volume       = 2,
	number       = 2
}
@inproceedings{raji2019actionable,
	title        = {Actionable auditing: Investigating the impact of publicly naming biased performance results of commercial ai products},
	author       = {Raji, Inioluwa Deborah and Buolamwini, Joy},
	year         = 2019,
	booktitle    = {Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society},
	pages        = {429--435}
}
@article{corbett2018measure,
	title        = {The measure and mismeasure of fairness: A critical review of fair machine learning},
	author       = {Corbett-Davies, Sam and Goel, Sharad},
	year         = 2018,
	journal      = {arXiv preprint arXiv:1808.00023}
}
@article{truthseeker,
	title        = {Fake news detection models using the largest social media ground-truth dataset (TruthSeeker)},
	author       = {Khalil, Maysa and Azzeh, Mohammad},
	year         = 2024,
	journal      = {International Journal of Speech Technology},
	publisher    = {Springer},
	pages        = {1--16}
}
@article{van2021fairness,
	title        = {Fairness as equal concession: critical remarks on fair AI},
	author       = {van Nood, Ryan and Yeomans, Christopher},
	year         = 2021,
	journal      = {Science and Engineering Ethics},
	publisher    = {Springer},
	volume       = 27,
	number       = 6,
	pages        = 73
}
@article{feuerriegel2020fair,
	title        = {Fair AI: Challenges and opportunities},
	author       = {Feuerriegel, Stefan and Dolata, Mateusz and Schwabe, Gerhard},
	year         = 2020,
	journal      = {Business \& information systems engineering},
	publisher    = {Springer},
	volume       = 62,
	pages        = {379--384}
}
@inproceedings{kdd-nsl,
	title        = {A detailed analysis of the KDD CUP 99 data set},
	author       = {Tavallaee, Mahbod and Bagheri, Ebrahim and Lu, Wei and Ghorbani, Ali A},
	year         = 2009,
	booktitle    = {2009 IEEE symposium on computational intelligence for security and defense applications},
	pages        = {1--6},
	organization = {Ieee}
}
@book{falco2006using,
	title        = {Using host-based anti-virus software on industrial control systems: Integration guidance and a test methodology for assessing performance impacts},
	author       = {Falco, Joseph A and Hurd, Steve and Teumim, Dave},
	year         = 2006,
	publisher    = {NIST}
}
@article{meyers2023safety,
	title        = {Safety-critical computer vision: an empirical survey of adversarial evasion attacks and defenses on computer vision systems},
	author       = {Meyers, Charles and L{\"o}fstedt, Tommy and Elmroth, Erik},
	journal      = {Artificial Intelligence Review},
	volume={56},
  number={Suppl 1},
  pages={217--251},
  year={2023},
  publisher={Springer},
}
@article{firenet,
	title        = {Can stable and accurate neural networks be computed},
	author       = {Colbrook, Matthew~J. and Antun, Vegard and Hansen, Anders~C.},
	year         = 2021,
	journal      = {On the barriers of deep learning and Smale's 18th problem. arXiv},
	volume       = 2101
}
@article{bienstock2018principled,
	title        = {Principled deep neural network training through linear programming},
	author       = {Bienstock, Daniel and Mu{\~n}oz, Gonzalo and Pokutta, Sebastian},
	year         = 2018,
	journal      = {arXiv:1810.03218}
}
@article{de2010optimized,
	title        = {Optimized fixed-size kernel models for large data sets},
	author       = {De Brabanter, Kris and De Brabanter, Jos and Suykens, Johan AK and De Moor, Bart},
	year         = 2010,
	journal      = {Computational Statistics \& Data Analysis},
	publisher    = {Elsevier},
	volume       = 54,
	number       = 6,
	pages        = {1484--1504}
}
@article{ai_automotive_safety,
	title        = {Autonomous vehicle accident data analysis: California OL 316 reports: 2015--2020},
	author       = {McCarthy, Roger L},
	year         = 2022,
	journal      = {ASCE-ASME Journal of Risk and Uncertainty in Engineering Systems, Part B: Mechanical Engineering},
	publisher    = {American Society of Mechanical Engineers},
	volume       = 8,
	number       = 3,
	pages        = {034502}
}
@article{goodman1993p,
	title        = {P values, hypothesis tests, and likelihood: implications for epidemiology of a neglected historical debate},
	author       = {Goodman, Steven N},
	year         = 1993,
	journal      = {American Journal of Epidemiology},
	publisher    = {Oxford University Press},
	volume       = 137,
	number       = 5,
	pages        = {485--496}
}
@article{crashgenderbias,
	title        = {The impact of sex on motor vehicle crash injury outcomes},
	author       = {Ryan, Alyssa and Tainter, Francis and Fitzpatrick, Cole and Gazzillo, Jennifer and Riessman, Robin and Knodler, Michael},
	year         = 2022,
	journal      = {Journal of Transportation Safety \& Security},
	publisher    = {Taylor \& Francis},
	volume       = 14,
	number       = 5,
	pages        = {818--842}
}
@article{indian_point,
	title        = {Nuclear power for AI: what it will take to reopen Three Mile Island safely},
	author       = {Greshko, Michael},
	year         = 2024,
	month        = sep,
	journal      = {Nature},
	doi          = {10.1038/d41586-024-03162-2},
	url          = {https://www.nature.com/articles/d41586-024-03162-2}
}
@article{ai_water,
	title        = {The environmental impact of ai: A case study of water consumption by chat gpt},
	author       = {George, A Shaji and George, AS Hovan and Martin, AS Gabrio},
	year         = 2023,
	journal      = {Partners Universal International Innovation Journal},
	volume       = 1,
	number       = 2,
	pages        = {97--104}
}
@article{ai_trucking,
	title        = {Intelligent and efficient? An empirical analysis of human--AI collaboration for truck drivers in retail logistics},
	author       = {Loske, Dominic and Klumpp, Matthias},
	year         = 2021,
	journal      = {The International Journal of Logistics Management},
	publisher    = {Emerald Publishing Limited},
	volume       = 32,
	number       = 4,
	pages        = {1356--1383}
}
@article{ai_inequity,
	title        = {Unmasking inequalities of the code: Disentangling the nexus of AI and inequality},
	author       = {Bircan, Tuba and {\"O}zbilgin, Mustafa F},
	year         = 2025,
	journal      = {Technological Forecasting and Social Change},
	publisher    = {Elsevier},
	volume       = 211,
	pages        = 123925
}
@article{fan2008liblinear,
	title        = {LIBLINEAR: A library for large linear classification},
	author       = {Fan, Rong-En and Chang, Kai-Wei and Hsieh, Cho-Jui and Wang, Xiang-Rui and Lin, Chih-Jen},
	year         = 2008,
	journal      = {the Journal of machine Learning research},
	publisher    = {JMLR. org},
	volume       = 9,
	pages        = {1871--1874}
}
@article{scikit-learn,
	title        = {Scikit-learn: Machine Learning in {P}ython},
	author       = {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V. and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P. and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
	year         = 2011,
	journal      = {Journal of Machine Learning Research},
	volume       = 12,
	pages        = {2825--2830}
}
@book{metric,
	title        = {Metric spaces},
	author       = {Searco\'id, Mi\'chea\'l},
	year         = 2006,
	publisher    = {Springer},
	address      = {London},
	isbn         = {978-1-84628-369-7}
}
@inproceedings{demontis2019adversarial,
	title        = {Why do adversarial attacks transfer? explaining transferability of evasion and poisoning attacks},
	author       = {Demontis, Ambra and Melis, Marco and Pintor, Maura and Jagielski, Matthew and Biggio, Battista and Oprea, Alina and Nita-Rotaru, Cristina and Roli, Fabio},
	year         = 2019,
	booktitle    = {28th $\{$USENIX$\}$ Security Symposium},
	pages        = {321--338}
}
@incollection{tzotsos2008support,
	title        = {Support vector machine classification for object-based image analysis},
	author       = {Tzotsos, Angelos and Argialas, Demetre},
	year         = 2008,
	booktitle    = {Object-Based Image Analysis},
	publisher    = {Springer},
	pages        = {663--677}
}
@inproceedings{zhang2019theoretically,
	title        = {Theoretically principled trade-off between robustness and accuracy},
	author       = {Zhang, Hongyang and Yu, Yaodong and Jiao, Jiantao and Xing, Eric and El Ghaoui, Laurent and Jordan, Michael},
	year         = 2019,
	booktitle    = {International Conference on Machine Learning},
	pages        = {7472--7482},
	organization = {PMLR}
}
@misc{Dua:2019,
	title        = {{UCI} Machine Learning Repository},
	author       = {Dua, Dheeru and Graff, Casey},
	year         = 2017,
	url          = {http://archive.ics.uci.edu/ml},
	institution  = {University of California, Irvine, School of Information and Computer Sciences}
}


@misc{joblib,
	url        = {https://joblib.readthedocs.io/en/stable/},
	author       = {Joblib Developers},
	year         = 2025,
	title          = {Joblib: running Python functions as pipeline jobs},
}


@misc{ax,
	url        = {https://ax.readthedocs.io/en/stable/#},
	author       = {Ax Developers},
	year         = 2025,
	title          = {AX: Adaptive Experimentation Platform},
}

@inproceedings{slurm,
  title={Slurm: Simple linux utility for resource management},
  author={Yoo, Andy B and Jette, Morris A and Grondona, Mark},
  booktitle={Workshop on job scheduling strategies for parallel processing},
  pages={44--60},
  year={2003},
  organization={Springer}
}

@misc{rq,
	title        = {RQ: Easy Job Queues for Python},
	author       = {Stamps},
	year         = 2025,
	url          = {https://python-rq.org/},
	institution  = {Stamps, an Indonesian CRM company}
}

@article{chang2011libsvm,
	title        = {LIBSVM: a library for support vector machines},
	author       = {Chang, Chih-Chung and Lin, Chih-Jen},
	year         = 2011,
	journal      = {ACM transactions on intelligent systems and technology (TIST)},
	publisher    = {Acm New York, NY, USA},
	volume       = 2,
	number       = 3,
	pages        = {1--27}
}
@article{carlini2019evaluating,
	title        = {On evaluating adversarial robustness},
	author       = {Carlini, Nicholas and Athalye, Anish and Papernot, Nicolas and Brendel, Wieland and Rauber, Jonas and Tsipras, Dimitris and Goodfellow, Ian and Madry, Aleksander and Kurakin, Alexey},
	year         = 2019,
	journal      = {arXiv:1902.06705}
}
@inproceedings{matthew_rocklin-proc-scipy-2015,
	title        = {Dask: Parallel Computation with Blocked algorithms and Task Scheduling},
	author       = {Matthew Rocklin},
	year         = 2015,
	booktitle    = {Proceedings of the 14th Python in Science Conference},
	pages        = {130--136},
	editor       = {Kathryn Huff and James Bergstra}
}
@inproceedings{mehmood2015svm,
	title        = {SVM for network anomaly detection using ACO feature subset},
	author       = {Mehmood, Tahir and Rais, Helmi B Md},
	year         = 2015,
	booktitle    = {2015 International symposium on mathematical sciences and computing research (iSMSC)},
	pages        = {121--126},
	organization = {IEEE}
}
@inproceedings{kim2003network,
	title        = {Network-based intrusion detection with support vector machines},
	author       = {Kim, Dong Seong and Park, Jong Sou},
	year         = 2003,
	booktitle    = {International Conference on Information Networking},
	pages        = {747--756},
	organization = {Springer}
}
@article{bect2017bayesian,
	title        = {Bayesian subset simulation},
	author       = {Bect, Julien and Li, Ling and Vazquez, Emmanuel},
	year         = 2017,
	journal      = {SIAM/ASA Journal on Uncertainty Quantification},
	publisher    = {SIAM},
	volume       = 5,
	number       = 1,
	pages        = {762--786}
}
@inproceedings{carlini2017towards,
	title        = {Towards evaluating the robustness of neural networks},
	author       = {Carlini, Nicholas and Wagner, David},
	year         = 2017,
	booktitle    = {IEEE symposium on security and privacy (sp)},
	pages        = {39--57},
	organization = {IEEE}
}
@article{li2016general,
	title        = {A general retraining framework for scalable adversarial classification},
	author       = {Li, Bo and Vorobeychik, Yevgeniy and Chen, Xinyun},
	year         = 2016,
	journal      = {Workshop on Adversarial Training, Neural Information Processing Systems}
}
@inproceedings{biggio2013evasion,
	title        = {Evasion attacks against machine learning at test time},
	author       = {Biggio, Battista and Corona, Igino and Maiorca, Davide and Nelson, Blaine and {\v{S}}rndi{\'c}, Nedim and Laskov, Pavel and Giacinto, Giorgio and Roli, Fabio},
	year         = 2013,
	booktitle    = {Joint European conference on machine learning and knowledge discovery in databases},
	pages        = {387--402},
	organization = {Springer}
}
@inproceedings{simon2019first,
	title        = {First-order adversarial vulnerability of neural networks and input dimension},
	author       = {Simon-Gabriel, Carl-Johann and Ollivier, Yann and Bottou, Leon and Sch{\"o}lkopf, Bernhard and Lopez-Paz, David},
	year         = 2019,
	booktitle    = {International Conference on Machine Learning},
	pages        = {5809--5817},
	organization = {PMLR}
}
@inproceedings{fredrikson2015model,
	title        = {Model inversion attacks that exploit confidence information and basic countermeasures},
	author       = {Fredrikson, Matt and Jha, Somesh and Ristenpart, Thomas},
	year         = 2015,
	booktitle    = {Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security},
	pages        = {1322--1333}
}
@inproceedings{dohmatob2019generalized,
	title        = {Generalized no free lunch theorem for adversarial robustness},
	author       = {Dohmatob, Elvis},
	year         = 2019,
	booktitle    = {International Conference on Machine Learning},
	pages        = {1646--1654},
	organization = {PMLR}
}
@article{szegedy2013intriguing,
	title        = {Intriguing properties of neural networks},
	author       = {Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
	year         = 2013,
	journal      = {International Conference on Learning Representations}
}
@article{stutz2019confidence,
	title        = {Confidence-Calibrated Adversarial Training: Towards Robust Models Generalizing Beyond the Attack Used During Training},
	author       = {Stutz, David and Hein, Matthias and Schiele, Bernt},
	year         = 2019,
	journal      = {International Conference on Machine Learning}
}
@article{tsipras2018robustness,
	title        = {Robustness may be at odds with accuracy},
	author       = {Tsipras, Dimitris and Santurkar, Shibani and Engstrom, Logan and Turner, Alexander and Madry, Aleksander},
	year         = 2018,
	journal      = {Int'l Conference on Learning Representations}
}
@article{athalye2018obfuscated,
	title        = {Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples},
	author       = {Athalye, Anish and Carlini, Nicholas and Wagner, David},
	year         = 2018,
	journal      = {Int. Conference on Machine Learning}
}
@article{uesato2018adversarial,
	title        = {Adversarial risk and the dangers of evaluating against weak attacks},
	author       = {Uesato, Jonathan and O'Donoghue, Brendan and Oord, Aaron van den and Kohli, Pushmeet},
	year         = 2018,
	journal      = {Proceedings of Machine Learning Research}
}
@article{cortes1995support,
	title        = {Support-vector networks},
	author       = {Cortes, Corinna and Vapnik, Vladimir},
	year         = 1995,
	journal      = {Machine learning},
	publisher    = {Springer},
	volume       = 20,
	number       = 3,
	pages        = {273--297}
}
@article{trafalis2007robust,
	title        = {Robust support vector machines for classification and computational issues},
	author       = {Trafalis, Theodore B and Gilbert, Robin C},
	year         = 2007,
	journal      = {Optimisation Methods and Software},
	publisher    = {Taylor \& Francis},
	volume       = 22,
	number       = 1,
	pages        = {187--198}
}
@article{bordes2005fast,
	title        = {Fast kernel classifiers with online and active learning},
	author       = {Bordes, Antoine and Ertekin, Seyda and Weston, Jason and Bottou, L{\'e}on},
	year         = 2005,
	journal      = {Journal of Machine Learning Research},
	volume       = 6,
	number       = {Sep},
	pages        = {1579--1619}
}
@article{bottou2007support,
	title        = {Support vector machine solvers},
	author       = {Bottou, L{\'e}on and Lin, Chih-Jen},
	year         = 2007,
	journal      = {Large scale kernel machines},
	publisher    = {MIT press Cambridge, MA},
	volume       = 3,
	number       = 1,
	pages        = {301--320}
}
@article{croce2020reliable,
	title        = {Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks},
	author       = {Croce, Francesco and Hein, Matthias},
	year         = 2020,
	journal      = {International Conference on Machine Learning}
}
@article{biggio2012poisoning,
	title        = {Poisoning attacks against support vector machines},
	author       = {Biggio, Battista and Nelson, Blaine and Laskov, Pavel},
	year         = 2012,
	journal      = {International Conference on Machine Learning}
}
@article{grosse2018limitations,
	title        = {The limitations of model uncertainty in adversarial settings},
	author       = {Grosse, Kathrin and Pfaff, David and Smith, Michael Thomas and Backes, Michael},
	year         = 2018,
	journal      = {arXiv:1812.02606}
}
@article{kotyan2019adversarial,
	title        = {Adversarial Robustness Assessment: Why both $L_0 $ and $L_\infty$ Attacks Are Necessary},
	author       = {Kotyan, Shashank and Vargas, Danilo Vasconcellos},
	year         = 2019,
	journal      = {arXiv:1906.06026}
}
@inproceedings{chen2017zoo,
	title        = {Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models},
	author       = {Chen, Pin-Yu and Zhang, Huan and Sharma, Yash and Yi, Jinfeng and Hsieh, Cho-Jui},
	year         = 2017,
	booktitle    = {Proceedings of the 10th ACM workshop on artificial intelligence and security},
	pages        = {15--26}
}
@article{brown2017adversarial,
	title        = {Adversarial patch},
	author       = {Brown, Tom B and Man{\'e}, Dandelion and Roy, Aurko and Abadi, Mart{\'\i}n and Gilmer, Justin},
	year         = 2017,
	journal      = {arXiv:1712.09665}
}
@article{liu2018dpatch,
	title        = {Dpatch: An adversarial patch attack on object detectors},
	author       = {Liu, Xin and Yang, Huanrui and Liu, Ziwei and Song, Linghao and Li, Hai and Chen, Yiran},
	year         = 2018,
	journal      = {arXiv:1806.02299}
}
@inproceedings{qin2019imperceptible,
	title        = {Imperceptible, robust, and targeted adversarial examples for automatic speech recognition},
	author       = {Qin, Yao and Carlini, Nicholas and Cottrell, Garrison and Goodfellow, Ian and Raffel, Colin},
	year         = 2019,
	booktitle    = {International conference on machine learning},
	pages        = {5231--5240},
	organization = {PMLR}
}
@article{brendel2017decision,
	title        = {Decision-based adversarial attacks: Reliable attacks against black-box machine learning models},
	author       = {Brendel, Wieland and Rauber, Jonas and Bethge, Matthias},
	year         = 2017,
	journal      = {arXiv:1712.04248}
}
@inproceedings{chen2020hopskipjumpattack,
	title        = {Hopskipjumpattack: A query-efficient decision-based attack},
	author       = {Chen, Jianbo and Jordan, Michael I and Wainwright, Martin J},
	year         = 2020,
	booktitle    = {2020 ieee symposium on security and privacy (sp)},
	pages        = {1277--1294},
	organization = {IEEE}
}
@article{li2017hyperband,
	title        = {Hyperband: A novel bandit-based approach to hyperparameter optimization},
	author       = {Li, Lisha and Jamieson, Kevin and DeSalvo, Giulia and Rostamizadeh, Afshin and Talwalkar, Ameet},
	year         = 2017,
	journal      = {The Journal of Machine Learning Research},
	publisher    = {JMLR. org},
	volume       = 18,
	number       = 1,
	pages        = {6765--6816}
}
@article{su2019one,
	title        = {One pixel attack for fooling deep neural networks},
	author       = {Su, Jiawei and Vargas, Danilo Vasconcellos and Sakurai, Kouichi},
	year         = 2019,
	journal      = {IEEE Transactions on Evolutionary Computation},
	publisher    = {IEEE},
	volume       = 23,
	number       = 5,
	pages        = {828--841}
}
@article{hansen2016cma,
	title        = {The CMA evolution strategy: A tutorial},
	author       = {Hansen, Nikolaus},
	year         = 2016,
	journal      = {arXiv:1604.00772}
}
@article{raghunathan2020understanding,
	title        = {Understanding and mitigating the tradeoff between robustness and accuracy},
	author       = {Raghunathan, Aditi and Xie, Sang Michael and Yang, Fanny and Duchi, John and Liang, Percy},
	year         = 2020,
	journal      = {International Conference on Machine Learning}
}
@article{xu2009robustness,
	title        = {Robustness and Regularization of Support Vector Machines.},
	author       = {Xu, Huan and Caramanis, Constantine and Mannor, Shie},
	year         = 2009,
	journal      = {Journal of machine learning research},
	volume       = 10,
	number       = 7
}
@article{bertsimas2019robust,
	title        = {Robust classification},
	author       = {Bertsimas, Dimitris and Dunn, Jack and Pawlowski, Colin and Zhuo, Ying Daisy},
	year         = 2019,
	journal      = {INFORMS Journal on Optimization},
	publisher    = {INFORMS},
	volume       = 1,
	number       = 1,
	pages        = {2--34}
}
@article{wang2014iteration,
	title        = {Iteration complexity of feasible descent methods for convex optimization},
	author       = {Wang, Po-Wei and Lin, Chih-Jen},
	year         = 2014,
	journal      = {The Journal of Machine Learning Research},
	publisher    = {JMLR. org},
	volume       = 15,
	number       = 1,
	pages        = {1523--1548}
}
@article{Meidan_2018,
	title        = {{N-BaIoT}--Network-Based Detection of {IoT} Botnet Attacks Using Deep Autoencoders},
	author       = {Meidan, Yair and Bohadana, Michael and Mathov, Yael and Mirsky, Yisroel and Shabtai, Asaf and Breitenbacher, Dominik and Elovici, Yuval},
	year         = 2018,
	month        = jul,
	journal      = {IEEE Pervasive Computing},
	publisher    = {Institute of Electrical and Electronics Engineers (IEEE)},
	volume       = 17,
	number       = 3,
	pages        = {12–22}
}
@article{liu_2020,
	title        = {{MadDroid}: Characterizing and Detecting Devious Ad Contents for Android Apps},
	author       = {Liu, Tianming and Wang, Haoyu and Li, Li and Luo, Xiapu and Dong, Feng and Guo, Yao and Wang, Liu and Bissyand\'{e}, Tegawend\'{e} and Klein, Jacques},
	year         = 2020,
	month        = apr,
	journal      = {Proceedings of The Web Conference 2020},
	publisher    = {ACM}
}
@article{ateniese2015hacking,
	title        = {Hacking smart machines with smarter ones: How to extract meaningful data from machine learning classifiers},
	author       = {Ateniese, Giuseppe and Mancini, Luigi V and Spognardi, Angelo and Villani, Antonio and Vitali, Domenico and Felici, Giovanni},
	year         = 2015,
	journal      = {International Journal of Security and Networks},
	publisher    = {Inderscience Publishers (IEL)},
	volume       = 10,
	number       = 3,
	pages        = {137--150}
}
@article{wang2019security,
	title        = {The security of machine learning in an adversarial setting: A survey},
	author       = {Wang, Xianmin and Li, Jing and Kuang, Xiaohui and Tan, Yu-an and Li, Jin},
	year         = 2019,
	journal      = {Journal of Parallel and Distributed Computing},
	publisher    = {Elsevier},
	volume       = 130,
	pages        = {12--23}
}
@article{miller2020adversarial,
	title        = {Adversarial learning targeting deep neural network classification: A comprehensive review of defenses against attacks},
	author       = {Miller, David J and Xiang, Zhen and Kesidis, George},
	year         = 2020,
	journal      = {Proceedings of the IEEE},
	publisher    = {IEEE},
	volume       = 108,
	number       = 3,
	pages        = {402--433}
}
@article{jagielski2018manipulate,
	title        = {Manipulating machine learning: Poisoning attacks and countermeasures for regression learning},
	author       = {Jagielski, Matthew, Alina Oprea, Battista Biggio, Chang Liu, Cristina Nita-Rotaru, and Bo Li},
	year         = 2018,
	journal      = {IEEE Symposium on Security and Privacy (SP)}
}
@inproceedings{deka2019adversarial,
	title        = {Adversarial Impact on Anomaly Detection in Cloud Datacenters},
	author       = {Deka, Pratyush Kr and Bhuyan, Monowar H and Kadobayashi, Youki and Elmroth, Erik},
	year         = 2019,
	booktitle    = {2019 IEEE 24th Pacific Rim International Symposium on Dependable Computing (PRDC)},
	pages        = {188--18809},
	organization = {IEEE}
}
@article{min2020curious,
	title        = {The curious case of adversarially robust models: More data can help, double descend, or hurt generalization},
	author       = {Min, Yifei and Chen, Lin and Karbasi, Amin},
	year         = 2020,
	journal      = {arXiv:2002.11080}
}
% number={1},
title = {Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks},
	url = {http://arxiv.org/abs/2003.01690},
	abstract = {The ﬁeld of defense strategies against adversarial attacks has signiﬁcantly grown over the last years, but progress is hampered as the evaluation of adversarial defenses is often insufﬁcient and thus gives a wrong impression of robustness. Many promising defenses could be broken later on, making it difﬁcult to identify the state-of-the-art. Frequent pitfalls in the evaluation are improper tuning of hyperparameters of the attacks, gradient obfuscation or masking. In this paper we ﬁrst propose two extensions of the PGD-attack overcoming failures due to suboptimal step size and problems of the objective function. We then combine our novel attacks with two complementary existing ones to form a parameter-free, computationally affordable and user-independent ensemble of attacks to test adversarial robustness. We apply our ensemble to over 50 models from papers published at recent top machine learning and computer vision venues. In all except one of the cases we achieve lower robust test accuracy than reported in these papers, often by more than 10\%, identifying several broken defenses.},
	language = {en},
	urldate = {2020-10-01},
	journal = {arXiv:2003.01690 [cs, stat]},
	author = {Croce, Francesco and Hein, Matthias},
	month = aug,
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {Croce and Hein - 2020 - Reliable evaluation of adversarial robustness with.pdf:C\:\\Users\\charlie\\Zotero\\storage\\R7F4DQN8\\Croce and Hein - 2020 - Reliable evaluation of adversarial robustness with.pdf:application/pdf}
}
% 1646-1654, 2019.
% volume={},
% number={},
@misc{abelson2021bugs,
	title        = {Bugs in our Pockets: The Risks of Client-Side Scanning},
	author       = {Hal Abelson and Ross Anderson and Steven M. Bellovin and Josh Benaloh and Matt Blaze and Jon Callas and Whitfield Diffie and Susan Landau and Peter G. Neumann and Ronald L. Rivest and Jeffrey I. Schiller and Bruce Schneier and Vanessa Teague and Carmela Troncoso},
	year         = 2021,
	eprint       = {2110.07450},
	archiveprefix = {arXiv},
	primaryclass = {cs.CR}
}
@article{power_consumption_ai,
	year         = 2024,
	month        = may,
	journal      = {Goldman Sachs},
	url          = {https://www.goldmansachs.com/insights/articles/AI-poised-to-drive-160-increase-in-power-demand}
}
@article{maalouf2011robust,
	title        = {Robust weighted kernel logistic regression in imbalanced and rare events data},
	author       = {Maalouf, Maher and Trafalis, Theodore B},
	year         = 2011,
	journal      = {Computational Statistics \& Data Analysis},
	publisher    = {Elsevier},
	volume       = 55,
	number       = 1,
	pages        = {168--183}
}
@article{undersampling,
	title        = {Under-sampling approaches for improving prediction of the minority class in an imbalanced dataset},
	author       = {Yen, S and Lee, Y},
	year         = 2006,
	journal      = {Lecture notes in control and information sciences},
	publisher    = {Springer},
	volume       = 344,
	pages        = 731
}
@article{geiping2020witches,
	title        = {Witches' brew: Industrial scale data poisoning via gradient matching},
	author       = {Geiping, Jonas and Fowl, Liam and Huang, W Ronny and Czaja, Wojciech and Taylor, Gavin and Moeller, Michael and Goldstein, Tom},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2009.02276}
}
@article{souri2022sleeper,
	title        = {Sleeper agent: Scalable hidden trigger backdoors for neural networks trained from scratch},
	author       = {Souri, Hossein and Fowl, Liam and Chellappa, Rama and Goldblum, Micah and Goldstein, Tom},
	year         = 2022,
	journal      = {Advances in Neural Information Processing Systems},
	volume       = 35,
	pages        = {19165--19178}
}
@inproceedings{aghakhani2021bullseye,
	title        = {Bullseye polytope: A scalable clean-label poisoning attack with improved transferability},
	author       = {Aghakhani, Hojjat and Meng, Dongyu and Wang, Yu-Xiang and Kruegel, Christopher and Vigna, Giovanni},
	year         = 2021,
	booktitle    = {2021 IEEE European symposium on security and privacy (EuroS\&P)},
	pages        = {159--178},
	organization = {IEEE}
}
@article{shafahi2018poison,
	title        = {Poison frogs! targeted clean-label poisoning attacks on neural networks},
	author       = {Shafahi, Ali and Huang, W Ronny and Najibi, Mahyar and Suciu, Octavian and Studer, Christoph and Dumitras, Tudor and Goldstein, Tom},
	year         = 2018,
	journal      = {Advances in neural information processing systems},
	volume       = 31
}
@article{turner2018clean,
	title        = {Clean-label backdoor attacks},
	author       = {Turner, Alexander and Tsipras, Dimitris and Madry, Aleksander},
	year         = 2018
}
@inproceedings{shokri2020bypassing,
	title        = {Bypassing backdoor detection algorithms in deep learning},
	author       = {Shokri, Reza and others},
	year         = 2020,
	booktitle    = {2020 IEEE European Symposium on Security and Privacy (EuroS\&P)},
	pages        = {175--183},
	organization = {IEEE}
}
@article{gu2017badnets,
	title        = {Badnets: Identifying vulnerabilities in the machine learning model supply chain},
	author       = {Gu, Tianyu and Dolan-Gavitt, Brendan and Garg, Siddharth},
	year         = 2017,
	journal      = {arXiv preprint arXiv:1708.06733}
}
@inproceedings{rawat2022devil,
	title        = {The devil is in the GAN: backdoor attacks and defenses in deep generative models},
	author       = {Rawat, Ambrish and Levacher, Killian and Sinn, Mathieu},
	year         = 2022,
	booktitle    = {European Symposium on Research in Computer Security},
	pages        = {776--783},
	organization = {Springer}
}
@inproceedings{correia2018copycat,
	title        = {Copycat cnn: Stealing knowledge by persuading confession with random non-labeled data},
	author       = {Correia-Silva, Jacson Rodrigues and Berriel, Rodrigo F and Badue, Claudine and De Souza, Alberto F and Oliveira-Santos, Thiago},
	year         = 2018,
	booktitle    = {2018 International joint conference on neural networks (IJCNN)},
	pages        = {1--8},
	organization = {IEEE}
}
@article{imblearn,
	title        = {Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning},
	author       = {Guillaume  Lema{{\^i}}tre and Fernando Nogueira and Christos K. Aridas},
	year         = 2017,
	journal      = {Journal of Machine Learning Research},
	volume       = 18,
	number       = 17,
	pages        = {1--5},
	url          = {http://jmlr.org/papers/v18/16-365}
}
@misc{sms_spam,
	title        = {{SMS Spam Collection}},
	author       = {Almeida, Tiago and Hidalgo, Jos},
	year         = 2011,
	note         = {{DOI}: https://doi.org/10.24432/C5CC84},
	howpublished = {UCI Machine Learning Repository}
}
@article{sshash,
	title        = {Sparse and skew hashing of k-mers},
	author       = {Pibiri, Giulio Ermanno},
	year         = 2022,
	journal      = {Bioinformatics},
	publisher    = {Oxford University Press},
	volume       = 38,
	number       = {Supplement\_1},
	pages        = {i185--i194}
}
@article{mercer,
	title        = {Eigenvalues of integral operators defined by smooth positive definite kernels},
	author       = {Ferreira, JC and Menegatto, VA2501172},
	year         = 2009,
	journal      = {Integral Equations and Operator Theory},
	publisher    = {Springer},
	volume       = 64,
	number       = 1,
	pages        = {61--81}
}
@article{kernels,
	title        = {Investigating the effect of different kernel functions on the performance of SVM for recognizing Arabic characters},
	author       = {Fadel, Sayed and Ghoniemy, Said and Abdallah, Mohamed and Sorra, Hussein Abu and Ashour, Amira and Ansary, Asif},
	year         = 2016,
	journal      = {Int. J. Adv. Comput. Sci. Appl},
	volume       = 7,
	number       = 1,
	pages        = {446--450}
}
@article{collett2023modelling,
	title        = {Modelling survival data},
	author       = {Collett, David},
	year         = 2015,
	booktitle    = {Modelling survival data in medical research},
	publisher    = {Springer}
}
@misc{apple_csam,
	title        = {CSAM Detection: A Technical Summary},
	author       = {Apple Inc.},
	year         = 2021,
	month        = aug,
	journal      = {apple.com},
	url          = {https://www.apple.com/child-safety/pdf/CSAM_Detection_Technical_Summary.pdf},
	language     = {en}
}
@article{abelson2024bugs,
	title        = {Bugs in our pockets: The risks of client-side scanning},
	author       = {Abelson, Harold and Anderson, Ross and Bellovin, Steven M and Benaloh, Josh and Blaze, Matt and Callas, Jon and Diffie, Whitfield and Landau, Susan and Neumann, Peter G and Rivest, Ronald L and others},
	year         = 2024,
	journal      = {Journal of Cybersecurity},
	publisher    = {Oxford University Press},
	volume       = 10,
	number       = 1,
	pages        = {tyad020}
}
@inproceedings{croce2020robustbench,
	title        = {RobustBench: a standardized adversarial robustness benchmark},
	author       = {Francesco Croce and Maksym Andriushchenko and Vikash Sehwag and Edoardo Debenedetti and Nicolas Flammarion and Mung Chiang and Prateek Mittal and Matthias Hein},
	year         = 2021,
	booktitle    = {Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
	url          = {https://openreview.net/forum?id=SSKZPJCt7B}
}
@article{scilipoti2024strong,
	title        = {A Strong Inductive Bias: Gzip for binary image classification},
	author       = {Scilipoti, Marco and Fuster, Marina and Ramele, Rodrigo},
	year         = 2024,
	journal      = {arXiv preprint arXiv:2401.07392}
}
@misc{trashfire,
	title        = {A Training Rate and Survival Heuristic for Inference and Robustness Evaluation (TRASHFIRE)},
	author       = {Charles Meyers and Mohammad Reza Saleh Sedghpour and Tommy L\"{o}fstedt and Erik Elmroth},
	year         = 2024,
	url          = {https://arxiv.org/abs/2401.13751},
	eprint       = {2401.13751},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}
% volume={},
% number={},
@inproceedings{nouwens2020dark,
	title        = {Dark patterns after the GDPR: Scraping consent pop-ups and demonstrating their influence},
	author       = {Nouwens, Midas and Liccardi, Ilaria and Veale, Michael and Karger, David and Kagal, Lalana},
	year         = 2020,
	booktitle    = {Proceedings of the 2020 CHI conference on human factors in computing systems},
	pages        = {1--13}
}
@article{navarro2001guided,
	title        = {A guided tour to approximate string matching},
	author       = {Navarro, Gonzalo},
	year         = 2001,
	journal      = {ACM computing surveys (CSUR)},
	publisher    = {ACM New York, NY, USA},
	volume       = 33,
	number       = 1,
	pages        = {31--88}
}
@misc{amnesty_encryption,
	title        = {{Encryption-- a matter of human rights}},
	author       = {Amnesty International},
	year         = 2016,
	month        = 3,
	url          = {https://www.amnesty.nl/content/uploads/2016/03/160322_encryption_-_a_matter_of_human_rights_-_def.pdf?x12112}
}
@article{metrics,
	title        = {A course in metric geometry},
	author       = {Burago, D},
	year         = 2001,
	journal      = {American Mathematical Society}
}
@article{chat_control,
	title        = {Bugs in our pockets: the risks of client-side scanning},
	author       = {Abelson, Harold and Anderson, Ross and Bellovin, Steven M and Benaloh, Josh and Blaze, Matt and Callas, Jon and Diffie, Whitfield and Landau, Susan and Neumann, Peter G and Rivest, Ronald L and Schiller, Jeffrey I and Schneier, Bruce and Teague, Vanessa and Troncoso, Carmela},
	year         = 2024,
	month        = jan,
	journal      = {Journal of Cybersecurity},
	publisher    = {Oxford University Press (OUP)},
	volume       = 10,
	number       = 1,
	doi          = {10.1093/cybsec/tyad020},
	issn         = {2057-2093},
	url          = {http://dx.doi.org/10.1093/cybsec/tyad020}
}
@inproceedings{jaro,
	title        = {A Comparison of String Distance Metrics for Name-Matching Tasks.},
	author       = {Cohen, William W and Ravikumar, Pradeep and Fienberg, Stephen E and others},
	year         = 2003,
	booktitle    = {IIWeb},
	volume       = 3,
	pages        = {73--78}
}
@misc{ansuz_email,
	title        = {GZIP KNN Follow up},
	author       = {Aaron P. MacSween},
	url          = {https://transitiontech.ca/cs/ml/gzip-knn-follow-up}
}
@misc{ansuz_browser,
	title        = {Browser-based GZIP KNN},
	author       = {Aaron P. MacSween},
	url          = {https://codeberg.org/ansuz/browser-gzip-knn}
}
@article{ddos,
	title        = {CICIoT2023: A real-time dataset and benchmark for large-scale attacks in IoT environment},
	author       = {Neto, Euclides Carlos Pinto and Dadkhah, Sajjad and Ferreira, Raphael and Zohourian, Alireza and Lu, Rongxing and Ghorbani, Ali A},
	year         = 2023,
	journal      = {Sensors},
	publisher    = {MDPI},
	volume       = 23,
	number       = 13,
	pages        = 5941
}
@article{reaction_time,
	title        = {Reaction time, speed of performance, and age},
	author       = {Welford, Alan T},
	year         = 1988,
	journal      = {Ann NY Acad Sci},
	volume       = 515,
	pages        = {1--17}
}
@misc{kddnsl,
	title        = {NSL-KDD},
	author       = {Mohi-ud-din, Ghulam},
	year         = 2018,
	publisher    = {IEEE Dataport},
	doi          = {10.21227/425a-3e55},
	url          = {https://dx.doi.org/10.21227/425a-3e55}
}
@article{shan2022monte,
	title        = {Monte Carlo cross-validation for a study with binary outcome and limited sample size},
	author       = {Shan, Guogen},
	year         = 2022,
	journal      = {BMC Medical Informatics and Decision Making},
	publisher    = {Springer},
	volume       = 22,
	number       = 1,
	pages        = 270
}
@article{tpe,
	title        = {Algorithms for hyper-parameter optimization},
	author       = {Bergstra, James and Bardenet, R{\'e}mi and Bengio, Yoshua and K{\'e}gl, Bal{\'a}zs},
	year         = 2011,
	journal      = {Advances in neural information processing systems},
	volume       = 24
}
@article{ncd,
	title        = {The similarity metric},
	author       = {Ming Li and Xin Chen and Xin Li and Bin Ma and Vitanyi, P.M.B.},
	year         = 2004,
	journal      = {IEEE Transactions on Information Theory},
	volume       = 50,
	number       = 12,
	pages        = {3250--3264},
	doi          = {10.1109/TIT.2004.838101},
	keywords     = {Bioinformatics;Computer science;Genomics;Phylogeny;Robustness;History;Data mining;Internet;Biology computing;Plagiarism;Dissimilarity distance;Kolmogorov complexity;language tree construction;normalized compression distance;normalized information distance;parameter-free data mining;phylogeny in bioinformatics;universal similarity metric}
}
@article{hamming_distance,
	title        = {A technique for counting ones in a binary computer},
	author       = {Wegner, Peter},
	year         = 1960,
	journal      = {Communications of the ACM},
	publisher    = {ACM New York, NY, USA},
	volume       = 3,
	number       = 5,
	pages        = 322
}
@article{deflate,
	title        = {Deflate compression algorithm},
	author       = {Oswal, Savan and Singh, Anjali and Kumari, Kirthi},
	year         = 2016,
	journal      = {International Journal of Engineering Research and General Science},
	publisher    = {Citeseer},
	volume       = 4,
	number       = 1,
	pages        = {430--436}
}
@misc{gzip,
	title        = {{GZIP}: Gnu Zip},
	author       = {Free Software Foundation},
	year         = {2009--2023},
	howpublished = {https://www.gnu.org/software/gzip/manual/gzip.html}
}
@misc{levenshtein,
	title        = {Levenshtein},
	author       = {rapidfuzz},
	year         = 2021,
	howpublished = {https://rapidfuzzrap.github.io/Levenshtein/}
}
@article{weinreich2023parameter,
	title        = {Parameter-Free Molecular Classification and Regression with Gzip},
	author       = {Weinreich, Jan and Probst, Daniel},
	year         = 2023
}
@inproceedings{nishida2011tweet,
	title        = {Tweet classification by data compression},
	author       = {Nishida, Kyosuke and Banno, Ryohei and Fujimura, Ko and Hoshide, Takahide},
	year         = 2011,
	booktitle    = {Proceedings of the 2011 international workshop on DETecting and Exploiting Cultural diversiTy on the social web},
	pages        = {29--34}
}
@article{knn_extensions,
	title        = {A review of various k-nearest neighbor query processing techniques},
	author       = {Dhanabal, Subramaniam and Chandramathi, SJIJCA},
	year         = 2011,
	journal      = {International Journal of Computer Applications},
	publisher    = {Citeseer},
	volume       = 31,
	number       = 7,
	pages        = {14--22}
}
@article{weigted_knn,
	title        = {The Distance-Weighted k-Nearest-Neighbor Rule},
	author       = {Dudani, Sahibsingh A.},
	year         = 1976,
	journal      = {IEEE Transactions on Systems, Man, and Cybernetics},
	volume       = {SMC-6},
	number       = 4,
	pages        = {325--327},
	doi          = {10.1109/TSMC.1976.5408784},
	keywords     = {Nearest neighbor searches;Error correction;Upper bound;H infinity control}
}
@article{saga,
	title        = {SAGA: A fast incremental gradient method with support for non-strongly convex composite objectives},
	author       = {Defazio, Aaron and Bach, Francis and Lacoste-Julien, Simon},
	year         = 2014,
	journal      = {Advances in neural information processing systems},
	volume       = 27
}
@article{opitz2023gzip,
	title        = {Gzip versus bag-of-words for text classification with KNN},
	author       = {Opitz, Juri},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2307.15002}
}
@article{jiang2022less,
	title        = {Less is More: Parameter-Free Text Classification with Gzip},
	author       = {Jiang, Zhiying and Yang, Matthew YR and Tsirlin, Mikhail and Tang, Raphael and Lin, Jimmy},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2212.09410}
}
@article{marks2023ai,
	title        = {AI Chatbots, health privacy, and challenges to HIPAA compliance},
	author       = {Marks, Mason and Haupt, Claudia E},
	year         = 2023,
	journal      = {Jama}
}
@article{mitrou2018data,
	title        = {Data protection, artificial intelligence and cognitive services: is the general data protection regulation (GDPR)‘artificial intelligence-proof’?},
	author       = {Mitrou, Lilian},
	year         = 2018,
	journal      = {Artificial Intelligence and Cognitive Services: Is the General Data Protection Regulation (GDPR)‘Artificial Intelligence-Proof}
}
@article{amal2011survey,
	title        = {Survey of nearest neighbor condensing techniques},
	author       = {Amal, MILOUD-AOUIDATE and Baba-Ali, Ahmed Riadh},
	year         = 2011,
	journal      = {International Journal of Advanced Computer Science and Applications},
	publisher    = {Citeseer},
	volume       = 2,
	number       = 11
}
@inproceedings{jagielski2020high,
	title        = {High accuracy and high fidelity extraction of neural networks},
	author       = {Jagielski, Matthew and Carlini, Nicholas and Berthelot, David and Kurakin, Alex and Papernot, Nicolas},
	year         = 2020,
	booktitle    = {29th USENIX security symposium (USENIX Security 20)},
	pages        = {1345--1362}
}
@article{bentley2020quantifying,
	title        = {Quantifying membership inference vulnerability via generalization gap and other model metrics},
	author       = {Bentley, Jason W and Gibney, Daniel and Hoppenworth, Gary and Jha, Sumit Kumar},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2009.05669}
}
@article{ncd_pitfalls,
	title        = {Common pitfalls using the normalized compression distance: What to watch out for in a compressor},
	author       = {Cebri{\'a}n, Manuel and Alfonseca, Manuel and Ortega, Alfonso},
	year         = 2005,
	journal      = {}
}
@misc{brotli_package,
	title        = {GitHub - google/brotli: Brotli compression format},
	author       = {google},
	year         = 2024,
	journal      = {GitHub},
	url          = {https://github.com/google/brotli},
	language     = {en}
}
@misc{bz2,
	author       = {muraroa.demon.co.uk},
	year         = 1998,
	month        = jul,
	journal      = {www.muraroa.demon.co.uk/},
	url          = {https://web.archive.org/web/19980704181204/http://www.muraroa.demon.co.uk/},
	language     = {en}
}
@misc{brotli,
	title        = {GitHub - google/brotli: Brotli compression format},
	author       = {Google Inc.},
	journal      = {GitHub},
	url          = {https://github.com/google/brotli},
	language     = {en}
}
@misc{bz2_comparison,
	title        = {7zip vs bz2 vs gzip},
	author       = {compressionratings.com},
	year         = 2016,
	month        = apr,
	journal      = {compressionratings.com},
	url          = {https://web.archive.org/web/20160424151609/http://compressionratings.com/comp.cgi?7-zip+9.12b++bzip2+1.0.5++gzip+1.3.3+-5},
	language     = {en}
}
@misc{brotli_comparison,
	title        = {Comparison of Brotli, Deflate, Zopfli, LZMA, LZHAM and Bzip2 Compression Algorithms},
	author       = {Alakuijala, Jyrki and Kliuchnikov, Evgenii and Szabadka, Zoltan and Vandevenne, Lode and Google Inc},
	year         = 2015,
	month        = sep,
	journal      = {Comprehensive R Archive Network},
	url          = {https://cran.r-project.org/web/packages/brotli/vignettes/brotli-2015-09-22.pdf},
	language     = {en}
}
@inproceedings{extraction_attack,
	title        = {High accuracy and high fidelity extraction of neural networks},
	author       = {Jagielski, Matthew and Carlini, Nicholas and Berthelot, David and Kurakin, Alex and Papernot, Nicolas},
	year         = 2020,
	booktitle    = {29th USENIX security symposium (USENIX Security 20)},
	pages        = {1345--1362}
}
@inproceedings{wang2021enhancing,
	title        = {Enhancing the transferability of adversarial attacks through variance tuning},
	author       = {Wang, Xiaosen and He, Kun},
	year         = 2021,
	booktitle    = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages        = {1924--1933}
}

@article{injectionattack,
  title={A systematic review of detection and prevention techniques of SQL injection attacks},
  author={Nasereddin, Mohammed and ALKhamaiseh, Ashaar and Qasaimeh, Malik and Al-Qassas, Raad},
  journal={Information Security Journal: A Global Perspective},
  volume={32},
  number={4},
  pages={252--265},
  year={2023},
  publisher={Taylor \& Francis}
}


@article{meyers2024massively,
  title={Massively parallel evasion attacks and the pitfalls of adversarial retraining},
  author={Charles Meyers, Tommy L{\"o}fstedt, and Erik Elmroth},
  journal={EAI Endorsed Transactions on Internet of Things},
  volume={10},
  year={2024},
  publisher={Gent EAI}
}
@article{firewallvuln,
  title={Research on Security Weakness Using Penetration Testing in a Distributed Firewall},
  author={Tudosi, Andrei-Daniel and Graur, Adrian and Balan, Doru Gabriel and Potorac, Alin Dan},
  journal={Sensors},
  volume={23},
  number={5},
  pages={2683},
  year={2023},
  publisher={MDPI}
}